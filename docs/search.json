[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kansas State workshop",
    "section": "",
    "text": "Distance sampling of several data sets\nThese are not intended to be complete analyses, but rather the initial steps in a thorough analysis of such data."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "rachel/rusten.html",
    "href": "rachel/rusten.html",
    "title": "Sandhills Grassland Birds",
    "section": "",
    "text": "Goal: Evaluate the effects of Eastern Redcedar removal treatments and management on avian communities in eastern Sandhills Ecoregion in Nebraska, USA\n\n\n\n\n\n\n\n\n\n\nBefore beginning, a note about point transects\n\n\n\n\n\n\nAnimal movement can bias distance sampling estimates\nBias is magnified when animals move faster than observers\nObservers are stationary during point counts\nSee Buckland (2006) regarding “snapshot moment” to alleviate bias"
  },
  {
    "objectID": "rachel/rusten.html#are-grassland-restoration-actions-of-woody-removal-benefiting-local-native-wildlife",
    "href": "rachel/rusten.html#are-grassland-restoration-actions-of-woody-removal-benefiting-local-native-wildlife",
    "title": "Sandhills Grassland Birds",
    "section": "",
    "text": "Goal: Evaluate the effects of Eastern Redcedar removal treatments and management on avian communities in eastern Sandhills Ecoregion in Nebraska, USA\n\n\n\n\n\n\n\n\n\n\nBefore beginning, a note about point transects\n\n\n\n\n\n\nAnimal movement can bias distance sampling estimates\nBias is magnified when animals move faster than observers\nObservers are stationary during point counts\nSee Buckland (2006) regarding “snapshot moment” to alleviate bias"
  },
  {
    "objectID": "cassidy/lathrom.html",
    "href": "cassidy/lathrom.html",
    "title": "Ft Riley bumblebees",
    "section": "",
    "text": "evaluate environmental factors affecting bumblebee density and abundance using distance sampling methods\n\n\n\n\n\n\n\nMultiple years of data, my approach\n\n\n\n\n\nThere are three years of survey data. The first year (2022) was described as a pilot survey, so I will not thoroughly examine the 2022 data."
  },
  {
    "objectID": "cassidy/lathrom.html#status-of-native-bumblebees-bombus-spp.-at-fort-riley-military-reservation-kansas",
    "href": "cassidy/lathrom.html#status-of-native-bumblebees-bombus-spp.-at-fort-riley-military-reservation-kansas",
    "title": "Ft Riley bumblebees",
    "section": "",
    "text": "evaluate environmental factors affecting bumblebee density and abundance using distance sampling methods"
  },
  {
    "objectID": "rachel/rusten.html#becoming-acquainted-with-data",
    "href": "rachel/rusten.html#becoming-acquainted-with-data",
    "title": "Sandhills Grassland Birds",
    "section": "Becoming acquainted with data",
    "text": "Becoming acquainted with data\n\nalldata &lt;- read.csv(file=\"data/Rusten_GrasslandBird_dist24.csv\")\n(numstrat &lt;- unique(alldata$Region.Label))\n\n [1] \"BLA049-C\"    \"Dismal E\"    \"Double E\"    \"Double M\"    \"Double W\"   \n [6] \"GAR-LOWja\"   \"GAR-ML-A\"    \"GAR-PLU\"     \"GAR-WIL-A\"   \"GAR-WIL-B\"  \n[11] \"GAR-WIL-C\"   \"GAR041-B\"    \"GAR045-A\"    \"GAR045-B\"    \"GAR046-A\"   \n[16] \"GAR046-B\"    \"GAR046-C\"    \"GAR046-H\"    \"GAR046-M\"    \"GAR053-A\"   \n[21] \"GAR053-B\"    \"GAR054\"      \"LOU-SMI-A\"   \"LOU-SMI-B\"   \"LOU-SMI-C\"  \n[26] \"LOU-SWMB\"    \"Valentine A\" \"Valentine B\" \"Weggener\"    \"WHE014\"     \n[31] \"WHE035-A\"    \"WHE035-B\"    \"WHE035-C\"   \n\n(numspec &lt;- unique(alldata$Species))\n\n [1] \"WEME\"  \"GRSP\"  NA      \"NOFL\"  \"WITU\"  \"BHCO\"  \"MODO\"  \"LASP\"  \"FISP\" \n[10] \"BLGR\"  \"CONI\"  \"AMCR\"  \"KILL\"  \"BARS\"  \"HOLA\"  \"RTHA\"  \"RHWO\"  \"AGOL\" \n[19] \"AMRO\"  \"BLJA\"  \"SPTO\"  \"NOCA\"  \"DICK\"  \"CLSW\"  \"UPSA\"  \"LBCO\"  \"NOBO\" \n[28] \"WEKI\"  \"BEVI\"  \"RWBL\"  \"HOWR\"  \"EAKI\"  \"GRCA\"  \"BRTH\"  \"CHSP\"  \"SOSP\" \n[37] \"OROR\"  \"NODO\"  \"YEWA\"  \"BAOR\"  \"COGR\"  \"MALL\"  \"BOBO\"  \"MODI\"  \"AMCK\" \n[46] \"MAKE\"  \"HCWR\"  \"NOFC\"  \"WISN\"  \"BWTE\"  \"YHBL\"  \"MAWR\"  \"NOPI\"  \"EUST\" \n[55] \"COYE\"  \"WIPH\"  \"AMBI\"  \"SORA\"  \"AMKE\"  \"LOSH\"  \"TRES\"  \"EUCD\"  \"YBCH\" \n[64] \"GTGR\"  \"WAVI\"  \"COHA\"  \"STGR\"  \"TUVU\"  \"UNSP\"  \"RWRL\"  \"REVI\"  \"SPTP\" \n[73] \"RNEP\"  \"EATO\"  \"BBHCO\" \"BBCH\"  \"NRWS\"  \"CANG\"  \"VESP\"  \"GRPC\"  \"WODU\" \n[82] \"RINP\"  \"AWPE\"  \"SWSP\"  \"BCOH\"  \"BAEA\"  \"CEWA\"  \"LBCU\"  \"GCFL\"  \"INBU\" \n[91] \"SWHA\" \n\n\nGoodness, there are 91 species recorded during the 2024 field season. Let’s focus attention upon four species of interest: GRSP, WEME, DICK, UPSA:\n\nfourspec &lt;- subset(alldata, subset = Species %in% c(\"GRSP\", \"WEME\", \"DICK\", \"UPSA\"))\ntable(fourspec$Region.Label, fourspec$Species)\n\n             \n              DICK GRSP UPSA WEME\n  BLA049-C       0   34    0   47\n  Dismal E      29   47    1   48\n  Double E       8   22   10   55\n  Double M       2   66    0   42\n  Double W      28   49    0   24\n  GAR-LOWja     17   15    1    5\n  GAR-ML-A      32   32    1   31\n  GAR-PLU       31   24    0   25\n  GAR-WIL-A     21   14    6   21\n  GAR-WIL-B     13   33    0   30\n  GAR-WIL-C     26   54    0   38\n  GAR041-B      31   26    0   21\n  GAR045-A       1   43    4   30\n  GAR045-B       0   75    8   51\n  GAR046-A      15   34    2   21\n  GAR046-B      22   21    0   21\n  GAR046-C      45   48    2   47\n  GAR046-H      41   51   10   36\n  GAR046-M      10   44    3   38\n  GAR053-A      36   54    1   36\n  GAR053-B      43   36    1   33\n  GAR054        50   56    2   38\n  LOU-SMI-A      7   41    3   34\n  LOU-SMI-B     34   59    5   51\n  LOU-SMI-C     18   43    3   29\n  LOU-SWMB      52   42    0   27\n  Valentine A    9   17    4   17\n  Valentine B   19   12    5   20\n  Weggener       0   45    2   47\n  WHE014        26   28    1   37\n  WHE035-A      17   22    0   18\n  WHE035-B      44   58    0   49\n  WHE035-C      36   21    0   30\n\n\nDetections by Region.Label may be a bit sparse, particularly for UPSA. Let’s see how number of detections changes if we aggregate at the level of Group.\n\ntable(fourspec$Group, fourspec$Species)\n\n           \n            DICK GRSP UPSA WEME\n  BLA049       0   34    0   47\n  FS          67  229   13  216\n  GAR-LOW     17   15    1    5\n  GAR-ML      32   32    1   31\n  GAR-WIL     60  101    6   89\n  GAR041      31   26    0   21\n  GAR045       1  118   12   81\n  GAR046     133  198   17  163\n  GAR053      79   90    2   69\n  GAR054      50   56    2   38\n  GARPLU      31   24    0   25\n  LOU-SMI     59  143   11  114\n  LOU-SW      52   42    0   27\n  Valentine   28   29    9   37\n  WHE014      26   28    1   37\n  WHE035      97  101    0   97\n\n\nThat is an improvement.\n\nTransects within Region.Label or Group\nI’m unsure about the naming scheme for points stations. It seems most sensible for transects to “belong” to strata, but the numbering system does not seem to follow that. Perhaps using GridPointID as Sample.Label makes more sense? In most instances, it seems there are 12 replicate GridPointID values.\n\nunique(fourspec$GridPointID[fourspec$Region.Label==\"Double W\"])\n\n [1] \"Double W-194\" \"Double W-21\"  \"Double W-247\" \"Double W-372\" \"Double W-385\"\n [6] \"Double W-427\" \"Double W-478\" \"Double W-529\" \"Double W-610\" \"Double W-764\"\n[11] \"Double W-851\" \"Double W-904\"\n\n\nI’ll modify the working data frame to make GridPointID the point transect identified Sample.Label.\n\nfourspec$Sample.Label &lt;- fourspec$GridPointID\n\n\n\nBirds in flocks\nIs this of significance?\n\ntable(fourspec$Species, fourspec$Flock)\n\n      \n          1    2    3    4    5\n  DICK  746   13    4    0    0\n  GRSP 1248   14    2    1    1\n  UPSA   72    2    1    0    0\n  WEME 1075   13    8    1    0\n\n\nOnly 2.2% of dickcissel detections were of flocks &gt;1 individual, which is unlikely to alter the abundance/density estimates noticeably.\nWe will see if that makes a difference."
  },
  {
    "objectID": "rachel/rusten.html#exploratory-data-analysis-of-detection-distances",
    "href": "rachel/rusten.html#exploratory-data-analysis-of-detection-distances",
    "title": "Sandhills Grassland Birds",
    "section": "Exploratory data analysis of detection distances",
    "text": "Exploratory data analysis of detection distances\n\n\n\n\n\n\nDistances recorded as -1\n\n\n\n\n\nDon’t know why they exist, but they mess with detection function fitting, I’m throwing them out\n\n\n\n\nfourspec &lt;- subset(fourspec, subset = distance&gt; -1)\n\nhist(fourspec$distance[fourspec$Species==\"GRSP\"], \n     main=\"GRSP\", xlab=\"Radial distance\", nc=40)\nhist(fourspec$distance[fourspec$Species==\"WEME\"], \n     main=\"WEME\", xlab=\"Radial distance\", nc=40)\nhist(fourspec$distance[fourspec$Species==\"DICK\"], \n     main=\"DICK\", xlab=\"Radial distance\", nc=40)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProbably rounding of distances for meadowlark around 200 and 300m, but that shouldn’t cause problems."
  },
  {
    "objectID": "rachel/rusten.html#simple-analysis-for-estimates-at-the-group-level",
    "href": "rachel/rusten.html#simple-analysis-for-estimates-at-the-group-level",
    "title": "Sandhills Grassland Birds",
    "section": "Simple analysis for estimates at the Group level",
    "text": "Simple analysis for estimates at the Group level\nStandard practice will be to remove 10% most distant detections.\n\nlibrary(Distance)\n\nLoading required package: mrds\n\n\nThis is mrds 3.0.0\nBuilt: R 4.4.1; ; 2024-10-23 19:10:34 UTC; windows\n\n\n\nAttaching package: 'Distance'\n\n\nThe following object is masked from 'package:mrds':\n\n    create.bins\n\ncu &lt;- convert_units(\"meter\", NULL, \"hectare\")\nweme &lt;- subset(fourspec, Species==\"WEME\")\nweme.hn &lt;- ds(data=weme, transect = \"point\",\n         key=\"hn\", truncation = \"10%\",  convert_units = cu, adjustment = \"herm\")\n\nStarting AIC adjustment term selection.\n\n\nFitting half-normal key function\n\n\nAIC= 10176.094\n\n\nFitting half-normal key function with Hermite(4) adjustments\n\n\nAIC= 10167.679\n\n\nFitting half-normal key function with Hermite(4,6) adjustments\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis greater than 1 at some distances\n\n\nAIC= 10169.671\n\n\n\nHalf-normal key function with Hermite(4) adjustments selected.\n\nweme.uncos &lt;- ds(data=weme, transect = \"point\",\n         key=\"unif\", truncation = \"10%\",  convert_units = cu)\n\nStarting AIC adjustment term selection.\n\n\nFitting uniform key function\n\n\nAIC= 10752.837\n\n\nFitting uniform key function with cosine(1) adjustments\n\n\nAIC= 10162.97\n\n\nFitting uniform key function with cosine(1,2) adjustments\n\n\nAIC= 10164.74\n\n\n\nUniform key function with cosine(1) adjustments selected.\n\nweme.hr &lt;- ds(data=weme, transect = \"point\",\n         key=\"hr\", truncation = \"10%\",  convert_units = cu, adjustment = \"poly\")\n\nStarting AIC adjustment term selection.\n\n\nFitting hazard-rate key function\n\n\nAIC= 10125.116\n\n\nFitting hazard-rate key function with simple polynomial(4) adjustments\n\n\nAIC= 10127.116\n\n\n\nHazard-rate key function selected.\n\nsummarize_ds_models(weme.hn, weme.uncos, weme.hr)\n\n                 Model\n3    \\\\texttt{weme.hr}\n2 \\\\texttt{weme.uncos}\n1    \\\\texttt{weme.hn}\n                                                    Key function Formula\n3                                                    Hazard-rate      ~1\n2                 Uniform with cosine adjustment term of order 1    &lt;NA&gt;\n1 Half-normal with Hermite polynomial adjustment term of order 4      ~1\n  C-vM p-value $\\\\hat{P_a}$ se($\\\\hat{P_a}$) $\\\\Delta$AIC\n3 0.0446337078    0.4130381      0.017163665      0.00000\n2 0.0004631091    0.3490043      0.006997644     37.85355\n1 0.0028774891    0.4031840      0.043259167     42.56221\n\nplot(weme.hr, pdf=TRUE, nc=40, main=\"WEME, HR, pooled detfn\")\n\n\n\n\n\n\n\n\n\ncu &lt;- convert_units(\"meter\", NULL, \"hectare\")\ndick &lt;- fourspec[fourspec$Species==\"DICK\",]\ndick.hn &lt;- ds(data=dick, transect = \"point\",\n         key=\"hn\", truncation = \"10%\",  convert_units = cu, adjustment = \"herm\")\n\nStarting AIC adjustment term selection.\n\n\nFitting half-normal key function\n\n\nAIC= 6761.816\n\n\nFitting half-normal key function with Hermite(4) adjustments\n\n\nAIC= 6734.482\n\n\nFitting half-normal key function with Hermite(4,6) adjustments\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis greater than 1 at some distances\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis greater than 1 at some distances\n\n\nAIC= 6735.127\n\n\n\nHalf-normal key function with Hermite(4) adjustments selected.\n\ndick.uncos &lt;- ds(data=dick, transect = \"point\",\n         key=\"unif\", truncation = \"10%\",  convert_units = cu)\n\nStarting AIC adjustment term selection.\n\n\nFitting uniform key function\n\n\nAIC= 7054.786\n\n\nFitting uniform key function with cosine(1) adjustments\n\n\nAIC= 6755.077\n\n\nFitting uniform key function with cosine(1,2) adjustments\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis greater than 1 at some distances\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis greater than 1 at some distances\n\n\nAIC= 6725.678\n\n\nFitting uniform key function with cosine(1,2,3) adjustments\n\n\n** Warning: Maximum probability of detection is greater than one: invalid model fitted **\n** Warning: Maximum probability of detection is greater than one: invalid model fitted **\n** Warning: Maximum probability of detection is greater than one: invalid model fitted **\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis not weakly monotonic!\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis not strictly monotonic!\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis greater than 1 at some distances\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis not weakly monotonic!\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis not strictly monotonic!\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis greater than 1 at some distances\n\n\nAIC= 6723.171\n\n\nFitting uniform key function with cosine(1,2,3,4) adjustments\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis not strictly monotonic!\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis not strictly monotonic!\n\n\nAIC= 6715.747\n\n\nFitting uniform key function with cosine(1,2,3,4,5) adjustments\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis not strictly monotonic!\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis not strictly monotonic!\n\n\nAIC= 6716.003\n\n\n\nUniform key function with cosine(1,2,3,4) adjustments selected.\n\n\nWarning in mrds::check.mono(model, n.pts = 10): Detection function is not\nstrictly monotonic!\n\ndick.hr &lt;- ds(data=dick, transect = \"point\",\n         key=\"hr\", truncation = \"10%\",  convert_units = cu, adjustment = \"poly\")\n\nStarting AIC adjustment term selection.\n\n\nFitting hazard-rate key function\n\n\nAIC= 6708.399\n\n\nFitting hazard-rate key function with simple polynomial(4) adjustments\n\n\nAIC= 6710.399\n\n\n\nHazard-rate key function selected.\n\nsummarize_ds_models(dick.hn, dick.uncos, dick.hr)\n\n                 Model\n3    \\\\texttt{dick.hr}\n2 \\\\texttt{dick.uncos}\n1    \\\\texttt{dick.hn}\n                                                    Key function Formula\n3                                                    Hazard-rate      ~1\n2          Uniform with cosine adjustment terms of order 1,2,3,4    &lt;NA&gt;\n1 Half-normal with Hermite polynomial adjustment term of order 4      ~1\n  C-vM p-value $\\\\hat{P_a}$ se($\\\\hat{P_a}$) $\\\\Delta$AIC\n3  0.030839941    0.5151049       0.02079957      0.00000\n2  0.008889366    0.4895714       0.11422470      7.34863\n1  0.000541476    0.4498981       0.06111644     26.08327\n\nplot(dick.hr, pdf=TRUE, nc=40, main=\"DICK, HR, pooled detfn\")\n\n\n\n\n\n\n\n\n\ncu &lt;- convert_units(\"meter\", NULL, \"hectare\")\ngrsp &lt;- fourspec[fourspec$Species==\"GRSP\",]\ngrsp.hn &lt;- ds(data=grsp, transect = \"point\",\n         key=\"hn\", truncation = \"10%\",  convert_units = cu, adjustment = \"herm\")\n\nStarting AIC adjustment term selection.\n\n\nFitting half-normal key function\n\n\nAIC= 10188.996\n\n\nFitting half-normal key function with Hermite(4) adjustments\n\n\nAIC= 10191.08\n\n\n\nHalf-normal key function selected.\n\ngrsp.uncos &lt;- ds(data=grsp, transect = \"point\",\n         key=\"unif\", truncation = \"10%\",  convert_units = cu)\n\nStarting AIC adjustment term selection.\n\n\nFitting uniform key function\n\n\nAIC= 10361.471\n\n\nFitting uniform key function with cosine(1) adjustments\n\n\nAIC= 10196.275\n\n\nFitting uniform key function with cosine(1,2) adjustments\n\n\nAIC= 10185.799\n\n\nFitting uniform key function with cosine(1,2,3) adjustments\n\n\nAIC= 10186.734\n\n\n\nUniform key function with cosine(1,2) adjustments selected.\n\ngrsp.hr &lt;- ds(data=grsp, transect = \"point\",\n         key=\"hr\", truncation = \"10%\",  convert_units = cu, adjustment = \"poly\")\n\nStarting AIC adjustment term selection.\n\n\nFitting hazard-rate key function\n\n\nAIC= 10188.776\n\n\nFitting hazard-rate key function with simple polynomial(4) adjustments\n\n\nAIC= 10190.153\n\n\n\nHazard-rate key function selected.\n\nsummarize_ds_models(grsp.hn, grsp.uncos, grsp.hr)\n\n                 Model                                      Key function\n2 \\\\texttt{grsp.uncos} Uniform with cosine adjustment terms of order 1,2\n3    \\\\texttt{grsp.hr}                                       Hazard-rate\n1    \\\\texttt{grsp.hn}                                       Half-normal\n  Formula C-vM p-value $\\\\hat{P_a}$ se($\\\\hat{P_a}$) $\\\\Delta$AIC\n2    &lt;NA&gt;    0.2498221    0.5978788       0.05379185     0.000000\n3      ~1    0.2614903    0.6271652       0.03066799     2.976262\n1      ~1    0.2182570    0.5401211       0.02297043     3.196061\n\nplot(grsp.uncos, pdf=TRUE, nc=25, main=\"GRSP, unicos, pooled detfn\")"
  },
  {
    "objectID": "rachel/rusten.html#constant-detectability-across-strata",
    "href": "rachel/rusten.html#constant-detectability-across-strata",
    "title": "Sandhills Grassland Birds",
    "section": "Constant detectability across strata?",
    "text": "Constant detectability across strata?\nClearly there are insufficient detections within strata to fit stratum-specific detection functions. However, as shown in Rexstad et al. (2023), bias will result from using a pooled detection function to estimate density at the stratum level if detectability differs between strata.\nThe defensible way to estimate stratum-specific detection probabilities with small stratum-specific detections is to use stratum as a covariate. This may not work for the large number of strata we have here. The hazard rate model was preferred for two of the three species and it was second-preferred for the GRSP, so attempt covariate modelling using hazard rate as key function.\n\nweme.hrstrat &lt;- ds(data=weme, transect=\"point\", key=\"hr\", truncation=\"10%\",\n                   convert_units = cu, formula=~Region.Label)\ndick.hrstrat &lt;- ds(data=dick, transect=\"point\", key=\"hr\", truncation=\"10%\",\n                   convert_units = cu, formula=~Region.Label)\ngrsp.hrstrat &lt;- ds(data=grsp, transect=\"point\", key=\"hr\", truncation=\"10%\",\n                   convert_units = cu, formula=~Region.Label)\n\n\n\n\n\n\n\nConvergence warning)\n\n\n\n\n\nThere are convergence problems with the meadowlark data when using stratum as a covariate\n\n\n\nContrast models with and without Region.Label covariate for each species to provide an evidence-based assessment of constant detectability across strata.\n\nAIC(weme.hr, weme.hrstrat)\nAIC(dick.hr, dick.hrstrat)\nAIC(grsp.uncos, grsp.hrstrat)\n\nIf you are fussy, you could use BIC rather than AIC.\nAs an experiment, use Group as strata and fit group as a covariate. Won’t work because Area specified for the grid, not group.\n\nexperiment &lt;- fourspec\nexperiment$Region.Label &lt;- experiment$Group\nweme.group &lt;- subset(experiment, Species==\"WEME\")\nweme.hrgroup &lt;- ds(data=weme.group, transect=\"point\", key=\"hr\", truncation=\"10%\",\n                   convert_units = cu, formula=~Region.Label)\n\nDifferent idea, remove Region.Label for which there are fewer than 13 detections\n\nweme.small &lt;- subset(weme, subset = !(Region.Label %in% \n                       c(\"GAR-LOWja\", \"GAR046-B\", \"WHE035-A\", \"GAR041-B\")))\nweme.hrsmall &lt;- ds(data=weme.small, transect=\"point\", key=\"hr\", truncation=\"10%\",\n                   convert_units = cu, formula=~Region.Label)\n\nModel contains covariate term(s): no adjustment terms will be included.\n\n\nFitting hazard-rate key function\n\n\n** Warning: Estimation routine failed to converge due to an unknown error in iteration  10. Using results from previous iteration. **\n\n\n** Warning: Estimation routine failed to converge due to an unknown error in iteration  10. Using results from previous iteration. **\n\n\nAIC= 9104.442\n\nsummary(weme.hrsmall)\n\n\nSummary for distance analysis \nNumber of observations :  931 \nDistance range         :  0  -  190 \n\nModel       : Hazard-rate key function \nAIC         :  9104.442 \nOptimisation:  mrds (nlminb) \n\nDetection function parameters\nScale coefficient(s):  \n                           estimate          se\n(Intercept)              4.94688677  0.08271534\nRegion.LabelDismal E    -0.09894917  0.10408948\nRegion.LabelDouble E    -0.47962195  0.10334780\nRegion.LabelDouble M    -0.76186827  0.10063357\nRegion.LabelDouble W     0.16641743  0.14992042\nRegion.LabelGAR-ML-A     0.06320761  0.11030486\nRegion.LabelGAR-PLU     -0.35631703  0.10872536\nRegion.LabelGAR-WIL-A    0.54238093  1.49198862\nRegion.LabelGAR-WIL-B   -0.04987397  0.10933576\nRegion.LabelGAR-WIL-C   -0.45760829  0.10029013\nRegion.LabelGAR045-A     0.01263989  0.11566731\nRegion.LabelGAR045-B    -0.66855315  0.10202471\nRegion.LabelGAR046-A    -0.17205518  0.12103144\nRegion.LabelGAR046-C    -0.25646789  0.09901466\nRegion.LabelGAR046-H    -0.18178105  0.10455669\nRegion.LabelGAR046-M     0.69993744 51.18457566\nRegion.LabelGAR053-A    -0.36301038  0.11013097\nRegion.LabelGAR053-B    -0.03883844  0.11074116\nRegion.LabelGAR054      -0.28683575  0.10289028\nRegion.LabelLOU-SMI-A    0.13368792  0.19739695\nRegion.LabelLOU-SMI-B   -0.31320242  0.09772663\nRegion.LabelLOU-SMI-C    0.70297334 62.78670693\nRegion.LabelLOU-SWMB     0.67090930 15.94811581\nRegion.LabelValentine A  0.02058852  0.14324142\nRegion.LabelValentine B -0.45269551  0.10841242\nRegion.LabelWeggener     0.71563515 71.51594812\nRegion.LabelWHE014       0.69959280 82.71080926\nRegion.LabelWHE035-B    -0.37006588  0.09665477\nRegion.LabelWHE035-C     0.09896944  0.13566152\n\nShape coefficient(s):  \n            estimate         se\n(Intercept) 1.979705 0.07298019\n\n                        Estimate           SE         CV\nAverage p              0.3976596   0.01395904 0.03510297\nN in covered region 2341.1981326 105.32868691 0.04498922\n\nSummary statistics:\n        Region   Area CoveredArea Effort   n   k       ER     se.ER      cv.ER\n1     BLA049-C  256.0   136.09379     12  41  12 3.416667 0.3361622 0.09838895\n2     Dismal E  256.0   136.09379     12  41  12 3.416667 0.5143153 0.15053130\n3     Double E  256.0   136.09379     12  55  12 4.583333 0.4344682 0.09479306\n4     Double M  256.0   136.09379     12  42  12 3.500000 0.2302831 0.06579517\n5     Double W  256.0   113.41149     10  21  10 2.100000 0.3480102 0.16571915\n6     GAR-ML-A  256.0   136.09379     12  29  12 2.416667 0.2289083 0.09472066\n7      GAR-PLU  170.7   102.07035      9  23   9 2.555556 0.3379313 0.13223397\n8    GAR-WIL-A  256.0   124.75264     11  12  11 1.090909 0.2845905 0.26087460\n9    GAR-WIL-B  256.0   136.09379     12  28  12 2.333333 0.2842676 0.12182898\n10   GAR-WIL-C  256.0   124.75264     11  38  11 3.454545 0.2073046 0.06000923\n11    GAR045-A  256.0   124.75264     11  30  11 2.727273 0.3835459 0.14063349\n12    GAR045-B  256.0   136.09379     12  51  12 4.250000 0.2500000 0.05882353\n13    GAR046-A  256.0   124.75264     11  18  11 1.636364 0.3377123 0.20637973\n14    GAR046-C  256.0   136.09379     12  47  12 3.916667 0.3128155 0.07986779\n15    GAR046-H  256.0   124.75264     11  34  11 3.090909 0.5633430 0.18225804\n16    GAR046-M  256.0   136.09379     12  22  12 1.833333 0.3658393 0.19954870\n17    GAR053-A  256.0   113.41149     10  36  10 3.600000 0.3399346 0.09442629\n18    GAR053-B  234.7   124.75264     11  28  11 2.545455 0.3659020 0.14374723\n19      GAR054  256.0   124.75264     11  38  11 3.454545 0.2816715 0.08153649\n20   LOU-SMI-A  256.0   136.09379     12  19  12 1.583333 0.3361622 0.21231299\n21   LOU-SMI-B  256.0   136.09379     12  51  12 4.250000 0.3046359 0.07167903\n22   LOU-SMI-C  256.0   136.09379     12  25  12 2.083333 0.2599048 0.12475430\n23    LOU-SWMB  256.0   136.09379     12  24  12 2.000000 0.2132007 0.10660036\n24 Valentine A  234.7   102.07035      9  14   9 1.555556 0.2939724 0.18898224\n25 Valentine B  256.0    79.38805      7  20   7 2.857143 0.3400680 0.11902381\n26    Weggener  256.0   136.09379     12  42  12 3.500000 0.3793935 0.10839813\n27      WHE014  256.0   136.09379     12  25  12 2.083333 0.4515685 0.21675290\n28    WHE035-B  256.0   136.09379     12  49  12 4.083333 0.4680445 0.11462314\n29    WHE035-C  256.0   113.41149     10  28  10 2.800000 0.4422166 0.15793451\n30       Total 7296.1  3674.53243    324 931 324 2.860505 0.0656242 0.02294147\n\nAbundance:\n         Label   Estimate         se        cv        lcl        ucl        df\n1     BLA049-C  118.66049  20.011946 0.1686488   85.08087  165.49326  90.79591\n2     Dismal E  140.97113  26.846040 0.1904364   95.77154  207.50277  28.05292\n3     Double E  391.94920  61.895406 0.1579169  286.83119  535.59089  81.58389\n4     Double M  524.28199  71.074210 0.1355649  401.69831  684.27373 175.66001\n5     Double W   57.00439  12.999251 0.2280395   36.03567   90.17454  32.01415\n6     GAR-ML-A   75.81499  11.199152 0.1477169   56.52832  101.68199  63.47384\n7      GAR-PLU  114.40337  22.033897 0.1925983   77.67435  168.50005  35.60456\n8    GAR-WIL-A   24.62778   6.428462 0.2610249   13.90169   43.62975  10.02306\n9    GAR-WIL-B   88.24336  15.478152 0.1754030   62.16708  125.25748  46.60986\n10   GAR-WIL-C  282.87149  36.753992 0.1299318  219.15488  365.11292 190.95330\n11    GAR045-A   92.75365  18.097234 0.1951108   62.68949  137.23576  36.70007\n12    GAR045-B  528.62876  72.038103 0.1362735  404.70766  690.49438 257.00229\n13    GAR046-A   77.21347  20.483979 0.2652902   45.22424  131.83018  27.17504\n14    GAR046-C  216.80166  29.102486 0.1342355  166.20928  282.79382  84.34695\n15    GAR046-H  148.52264  32.563684 0.2192506   94.63098  233.10521  20.89556\n16    GAR046-M   41.38322   8.257969 0.1995487   26.78795   63.93065  11.00000\n17    GAR053-A  244.86702  42.315231 0.1728090  174.19894  344.20335  95.68222\n18    GAR053-B   86.58026  16.704628 0.1929381   58.66022  127.78919  32.22465\n19      GAR054  202.70343  29.632389 0.1461859  151.89276  270.51113  97.99366\n20   LOU-SMI-A   44.84228  14.546958 0.3244027   23.81032   84.45204  58.67881\n21   LOU-SMI-B  262.40595  33.369428 0.1271672  204.11880  337.33728 103.16581\n22   LOU-SMI-C   47.02639   5.866745 0.1247543   35.77274   61.82031  11.00000\n23    LOU-SWMB   45.14534   4.812509 0.1066004   35.72761   57.04556  11.00000\n24 Valentine A   47.87426  12.883482 0.2691108   27.94818   82.00693  32.58941\n25 Valentine B  231.70097  42.552452 0.1836525  159.99499  335.54387  33.58330\n26    Weggener   79.00434   8.563922 0.1083981   62.27851  100.22213  11.00000\n27      WHE014   47.02639  10.193107 0.2167529   29.34447   75.36279  11.00000\n28    WHE035-B  281.59350  43.130847 0.1531671  206.69814  383.62657  34.81006\n29    WHE035-C   83.25713  18.586235 0.2232390   53.22301  130.23970  35.57257\n30       Total 4628.15883 177.036326 0.0382520 4293.48399 4988.92139 786.77691\n\nDensity:\n         Label   Estimate         se        cv        lcl       ucl        df\n1     BLA049-C 0.46351753 0.07817166 0.1686488 0.33234716 0.6464581  90.79591\n2     Dismal E 0.55066846 0.10486734 0.1904364 0.37410756 0.8105577  28.05292\n3     Double E 1.53105155 0.24177893 0.1579169 1.12043434 2.0921519  81.58389\n4     Double M 2.04797650 0.27763363 0.1355649 1.56913403 2.6729442 175.66001\n5     Double W 0.22267339 0.05077832 0.2280395 0.14076435 0.3522443  32.01415\n6     GAR-ML-A 0.29615229 0.04374669 0.1477169 0.22081376 0.3971953  63.47384\n7      GAR-PLU 0.67020136 0.12907965 0.1925983 0.45503425 0.9871122  35.60456\n8    GAR-WIL-A 0.09620226 0.02511118 0.2610249 0.05430349 0.1704287  10.02306\n9    GAR-WIL-B 0.34470064 0.06046153 0.1754030 0.24284014 0.4892870  46.60986\n10   GAR-WIL-C 1.10496676 0.14357028 0.1299318 0.85607377 1.4262223 190.95330\n11    GAR045-A 0.36231894 0.07069232 0.1951108 0.24488081 0.5360772  36.70007\n12    GAR045-B 2.06495609 0.28139884 0.1362735 1.58088930 2.6972437 257.00229\n13    GAR046-A 0.30161512 0.08001554 0.2652902 0.17665720 0.5149617  27.17504\n14    GAR046-C 0.84688148 0.11368158 0.1342355 0.64925501 1.1046634  84.34695\n15    GAR046-H 0.58016656 0.12720189 0.2192506 0.36965226 0.9105672  20.89556\n16    GAR046-M 0.16165322 0.03225769 0.1995487 0.10464044 0.2497291  11.00000\n17    GAR053-A 0.95651180 0.16529387 0.1728090 0.68046460 1.3445443  95.68222\n18    GAR053-B 0.36889757 0.07117439 0.1929381 0.24993701 0.5444789  32.22465\n19      GAR054 0.79181028 0.11575152 0.1461859 0.59333109 1.0566841  97.99366\n20   LOU-SMI-A 0.17516516 0.05682405 0.3244027 0.09300907 0.3298908  58.67881\n21   LOU-SMI-B 1.02502322 0.13034933 0.1271672 0.79733906 1.3177237 103.16581\n22   LOU-SMI-C 0.18369684 0.02291697 0.1247543 0.13973725 0.2414856  11.00000\n23    LOU-SWMB 0.17634897 0.01879886 0.1066004 0.13956096 0.2228342  11.00000\n24 Valentine A 0.20398064 0.05489340 0.2691108 0.11908044 0.3494117  32.58941\n25 Valentine B 0.90508191 0.16622051 0.1836525 0.62498045 1.3107182  33.58330\n26    Weggener 0.30861069 0.03345282 0.1083981 0.24327545 0.3914927  11.00000\n27      WHE014 0.18369684 0.03981682 0.2167529 0.11462685 0.2943859  11.00000\n28    WHE035-B 1.09997460 0.16847987 0.1531671 0.80741460 1.4985413  34.81006\n29    WHE035-C 0.32522316 0.07260248 0.2232390 0.20790240 0.5087488  35.57257\n30       Total 0.63433325 0.02426451 0.0382520 0.58846288 0.6837792 786.77691\n\n\nThe convergence may still not be perfect; however the CVs at the stratum level are reasonable, staying below 0.35.\n\nplot(weme.hrsmall, pdf=TRUE)\nrlabels &lt;- unique(weme.small$Region.Label)\nfor (i in 1:length(rlabels)) {\n  add_df_covar_line(weme.hrsmall, data=data.frame(Region.Label=rlabels[i]),\n                    lwd=2, lty=1, pdf=TRUE, col=colours(TRUE)[i])\n}\nlegend(\"topright\", title=\"Strata\", legend=rlabels,\n       lwd=2, lty=1, col=colours(TRUE), cex=0.8)\n\n\n\n\n\n\n\n\nThe plot of the probability density functions at the stratum level indicates one stratum with a very different detection function shape compared to the rest of the strata (WHE014). This may explain the convergence challenge. That stratum might be a candidate for exclusion.\n\nhist(weme$distance[weme$Region.Label==\"WHE014\"], xlim=c(0,190), nc=10,\n     xlab=\"Radial distance\", main=\"Stratum WHE014 detections of WEME\")\n\n\n\n\n\n\n\n\nNote the SE of the stratum-\\(\\hat{\\beta}\\) associated with stratum WHE014 82.7108093"
  },
  {
    "objectID": "cassidy/lathrom.html#becoming-acquainted-with-data",
    "href": "cassidy/lathrom.html#becoming-acquainted-with-data",
    "title": "Ft Riley bumblebees",
    "section": "Becoming acquainted with data",
    "text": "Becoming acquainted with data\nReorganise the data columns just a bit\n\nlibrary(readxl)\nyr22 &lt;- read_xlsx(path=\"data/2022-2024_bee_ds_data.xlsx\",\n                     sheet = \"2022\")\n\nNew names:\n• `Sample.Label` -&gt; `Sample.Label...5`\n• `Sample.Label` -&gt; `Sample.Label...12`\n\nyr23 &lt;- read_xlsx(path=\"data/2022-2024_bee_ds_data.xlsx\",\n                     sheet = \"2023\")\nyr24 &lt;- read_xlsx(path=\"data/2022-2024_bee_ds_data.xlsx\",\n                     sheet = \"2024\")\nyr22$Sample.Label...12 &lt;- NULL\nyr22$Sample.Label &lt;- yr22$Sample.Label...5\nyr22$Sample.Label...5 &lt;- NULL\nyr22 &lt;- yr22[yr22$distance&gt;=0,]  # a couple of -1 values\n(numstrat &lt;- unique(yr22$Region.Label))\n\n[1] NA     \"FRMR\"\n\n(numtrans &lt;- unique(yr22$Sample.Label))\n\n  [1]  NA   2   3   4   5   6   7   8   9  11  14  15  17  20  21  22  23  25\n [19]  26  28  29  30  32  33  34  35  36  37  38  39  40  41  42  43  44  45\n [37]  46  47  48  49  51  52  53  54  55  56  57  58  59  61  62  63  64  65\n [55]  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  83  84  85\n [73]  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103\n [91] 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121\n[109] 122 123 124 126 127 128 130 131 132 134 135 136 137 138 139 140 141 142\n[127] 143 144 145 146 147 148 149 150 151\n\n(numspec &lt;- unique(yr22$species))\n\n[1] NA          \"bombus\"    \"carpenter\" \"unknown\"   \"bumble\"   \n\n\n\nt22 &lt;- table(yr22$species, yr22$sample.bout)\nt23 &lt;- table(yr23$species, yr23$sample.bout)\nt24 &lt;- table(yr24$species, yr24$sample.bout)\n\nhistfn &lt;- function(frame, spec, bout) {\n  hist(frame$distance[frame$species==spec & frame$sample.bout==bout],\n       main=paste(spec, \" bout=\", bout), xlab=\"Distance\")\n}\nhistfn(yr22, \"bombus\", 1)\nhistfn(yr22, \"bombus\", 2)\nhistfn(yr22, \"carpenter\", 1)\nhistfn(yr22, \"carpenter\", 2)\nhistfn(yr22, \"unknown\", 1)\nhistfn(yr22, \"unknown\", 2)"
  },
  {
    "objectID": "cassidy/lathrom.html#construct-region-table-and-sample-tables",
    "href": "cassidy/lathrom.html#construct-region-table-and-sample-tables",
    "title": "Ft Riley bumblebees",
    "section": "4.1 Construct region table and sample tables",
    "text": "4.1 Construct region table and sample tables\n\n\n\n\n\n\nThe following step is critical\n\n\n\n\n\n\nIf the following specification of the survey design is not followed, the analysis will issue no complaints and will produce density estimates that appear to be quite wonderful.\nHowever, they will be wrong.\nBecause the stratum redefinition destroys the information about the survey design.\nInstead, the software assumes there were only transects on which detections of the species x bout combinations were made.\nAlways check the summary output from your fitted models to make sure the correct number of transects are represented.\n\n\n\n\n\nyr24$Region.Label &lt;- paste0(yr24$species, yr24$sample.bout)\nnew_region_table &lt;- data.frame(Region.Label=unique(yr24$Region.Label),\n                               Area=28383)\nnew_sample_table &lt;- data.frame(Sample.Label=rep(seq(1,151), 19),\n                               Region.Label=rep(unique(yr24$Region.Label), 151),\n                               Effort=rep(500, 19*151))\n\n\nyr24$Region.Label &lt;- paste0(yr24$species, yr24$sample.bout)\nyr24_hn_2level &lt;- ds(yr24, key=\"hn\", truncation = \"10%\", convert_units = cu,\n                     region_table = new_region_table,\n                     sample_table = new_sample_table,\n                     formula=~species+as.factor(sample.bout))\nyr24_hr_2level &lt;- ds(yr24, key=\"hr\", truncation = \"10%\", convert_units = cu,\n                     region_table = new_region_table,\n                     sample_table = new_sample_table,\n                     formula=~species+as.factor(sample.bout))\nyr24_hn_species &lt;- ds(yr24, key=\"hn\", truncation = \"10%\", convert_units = cu,\n                     region_table = new_region_table,\n                     sample_table = new_sample_table,\n                     formula=~species)\nyr24_hr_species &lt;- ds(yr24, key=\"hr\", truncation = \"10%\", convert_units = cu,\n                     region_table = new_region_table,\n                     sample_table = new_sample_table,\n                     formula=~species)\nyr24_hn_bout &lt;- ds(yr24, key=\"hn\", truncation = \"10%\", convert_units = cu,\n                     region_table = new_region_table,\n                     sample_table = new_sample_table,\n                     formula=~as.factor(sample.bout))\nyr24_hr_bout &lt;- ds(yr24, key=\"hr\", truncation = \"10%\", convert_units = cu,\n                     region_table = new_region_table,\n                     sample_table = new_sample_table,\n                     formula=~as.factor(sample.bout))\nyr24_hn &lt;- ds(yr24, key=\"hn\", truncation = \"10%\", convert_units = cu,\n                     region_table = new_region_table,\n                     sample_table = new_sample_table)\nyr24_hr &lt;- ds(yr24, key=\"hr\", truncation = \"10%\", convert_units = cu,\n                     region_table = new_region_table,\n                     sample_table = new_sample_table)\nknitr::kable(summarize_ds_models(#yr24_hn, yr24_hr, \n                    yr24_hn_bout, yr24_hr_bout, \n                    yr24_hn_species, yr24_hr_species, \n                    yr24_hn_2level, yr24_hr_2level)[, c(2:7)],\n             digits=3, row.names=FALSE,\n             caption=\"Model criticism candidate model set 2024\")\n\n\nModel criticism candidate model set 2024\n\n\n\n\n\n\n\n\n\n\nKey function\nFormula\nC-vM p-value\n\\(\\hat{P_a}\\)\nse(\\(\\hat{P_a}\\))\n\\(\\Delta\\)AIC\n\n\n\n\nHazard-rate\n~species + as.factor(sample.bout)\n0.854\n0.338\n0.014\n0.000\n\n\nHazard-rate\n~species\n0.831\n0.335\n0.014\n2.851\n\n\nHazard-rate\n~as.factor(sample.bout)\n0.955\n0.344\n0.014\n6.120\n\n\nHalf-normal\n~species + as.factor(sample.bout)\n0.000\n0.427\n0.008\n84.245\n\n\nHalf-normal\n~as.factor(sample.bout)\n0.000\n0.431\n0.008\n86.072\n\n\nHalf-normal\n~species\n0.000\n0.429\n0.008\n90.691\n\n\n\n\nknitr::kable(summary(yr24_hr_2level$ddf)$coeff$key.scale, \n             caption=\"Looking for convergence problems in covariate coefficients\")\n\n\nLooking for convergence problems in covariate coefficients\n\n\n\nestimate\nse\n\n\n\n\n(Intercept)\n2.3163705\n0.1768905\n\n\nspeciesamerican\n-0.1288956\n0.1958475\n\n\nspeciesblack_gold\n0.3598236\n0.2640821\n\n\nspeciesbombus\n0.2680591\n0.3690617\n\n\nspeciesbrown_belted\n0.0099796\n0.1846799\n\n\nspeciescarpenter\n-0.4039568\n0.1873527\n\n\nspecieseastern\n-0.0423246\n0.3281912\n\n\nspeciessouthern_plains\n0.0507996\n0.2260533\n\n\nspeciestwsp\n-0.1139367\n0.4077639\n\n\nspeciesunk\n-0.4962881\n0.2450548\n\n\nas.factor(sample.bout)2\n-0.2066934\n0.0939350"
  },
  {
    "objectID": "cassidy/lathrom.html#apply-this-function-to-the-yr24_hr_2level-fitted-model",
    "href": "cassidy/lathrom.html#apply-this-function-to-the-yr24_hr_2level-fitted-model",
    "title": "Ft Riley bumblebees",
    "section": "apply this function to the yr24_hr_2level fitted model",
    "text": "apply this function to the yr24_hr_2level fitted model\n\ncoefs &lt;- yr24_hr_2level$ddf$par\nxmax &lt;- 38.59703\nxvals &lt;- seq(0,xmax, length=100)\nam1 &lt;- gz(z=xvals, key=\"HR\",beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n          sigcoef = c(coefs[\"speciesamerican\"]))\nam2 &lt;- gz(z=xvals, key=\"HR\",beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n          sigcoef = c(coefs[\"speciesamerican\"], coefs[\"as.factor.sample.bout.2\"]))\nbomb1 &lt;- gz(z=xvals, key=\"HR\",beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n          sigcoef = c(coefs[\"speciesbombus\"]))\nbomb2 &lt;- gz(z=xvals, key=\"HR\",beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n          sigcoef = c(coefs[\"speciesbombus\"], coefs[\"as.factor.sample.bout.2\"]))\nplot(xvals, am1, type=\"l\")\nlines(xvals, am2, col=\"blue\")\nlines(xvals, bomb1, col=\"darkgreen\")\nlines(xvals, bomb2, col=\"red\")"
  },
  {
    "objectID": "cassidy/lathrom.html#now-for-the-integration-and-conversion-to-detection-probability",
    "href": "cassidy/lathrom.html#now-for-the-integration-and-conversion-to-detection-probability",
    "title": "Ft Riley bumblebees",
    "section": "now for the integration and conversion to detection probability",
    "text": "now for the integration and conversion to detection probability\n\nam1_p_int &lt;- integrate(gz, lower=0, upper=xmax, key=\"HR\",\n                    beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n                    sigcoef = c(coefs[\"speciesamerican\"]))$value / xmax\nam2_p_int &lt;- integrate(gz, lower=0, upper=xmax, key=\"HR\",\n                    beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n                    sigcoef = c(coefs[\"speciesamerican\"], coefs[\"as.factor.sample.bout.2\"]))$value / xmax\nbomb1_p_int &lt;- integrate(gz, lower=0, upper=xmax, key=\"HR\",\n                    beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n                    sigcoef = c(coefs[\"speciesbombus\"]))$value / xmax\nbomb2_p_int &lt;- integrate(gz, lower=0, upper=xmax, key=\"HR\",\n                    beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n                    sigcoef = c(coefs[\"speciesbombus\"], coefs[\"as.factor.sample.bout.2\"]))$value / xmax"
  },
  {
    "objectID": "cassidy/lathrom.html#do-the-integrated-pa-correspond-to-reported-densities",
    "href": "cassidy/lathrom.html#do-the-integrated-pa-correspond-to-reported-densities",
    "title": "Ft Riley bumblebees",
    "section": "4.5 Do the integrated Pa correspond to reported densities?",
    "text": "4.5 Do the integrated Pa correspond to reported densities?\nRecall our formula to estimate density:\n\\[\\hat{D} = \\frac{\\hat{P}_a \\cdot n}{a}\\] where \\(n\\) is number of detections and \\(a\\) is covered area. Both of these quantities appear in the fitted model object, along with \\(\\hat{D}\\) for each species x bout combination.\nWe can rearrange the above formula to solve for \\(\\hat{P}_a\\):\n\\[\\hat{P}_a = \\frac{n}{\\hat{D} \\cdot a}\\] The following code chunk carries out this method of deriving \\(\\hat{P}_a\\) and compares them with the original method of computing the integral of the detection function and dividing by truncation distance, \\(w\\).\n\nsumm &lt;- yr24_hr_2level$dht$individuals$summary\ncoveredarea &lt;- yr24_hr_2level$dht$individuals$summary$CoveredArea[1]\nd_est &lt;- yr24_hr_2level$dht$individuals$D\n\nam1_p_data &lt;- summ[summ$Region==\"american1\", \"n\"] / (d_est[d_est$Label==\"american1\", \"Estimate\"] * coveredarea)\nam2_p_data &lt;- summ[summ$Region==\"american2\", \"n\"] / (d_est[d_est$Label==\"american2\", \"Estimate\"] * coveredarea)\nbomb1_p_data &lt;- summ[summ$Region==\"bombus1\", \"n\"] / (d_est[d_est$Label==\"bombus1\", \"Estimate\"] * coveredarea)\nbomb2_p_data &lt;- summ[summ$Region==\"bombus2\", \"n\"] / (d_est[d_est$Label==\"bombus2\", \"Estimate\"] * coveredarea)\n\nall.equal(am1_p_int, am1_p_data)\n\n[1] \"Mean relative difference: 1.076724e-06\"\n\nall.equal(am2_p_int, am2_p_data)\n\n[1] \"Mean relative difference: 3.448128e-08\"\n\nall.equal(bomb1_p_int, bomb1_p_data)\n\n[1] \"Mean relative difference: 2.311959e-06\"\n\nall.equal(bomb2_p_int, bomb2_p_data)\n\n[1] \"Mean relative difference: 4.616678e-07\"\n\n\nYes, the integration results in a \\(\\hat{P}_a\\) equivalent to that used in the estimates produced by the software (as if there was any doubt).\nNow that the detection probability estimate dilemma is sorted, let’s look at the objects of ecological interest, namely the species- and bout-specific density estimates."
  },
  {
    "objectID": "cassidy/lathrom.html#objective",
    "href": "cassidy/lathrom.html#objective",
    "title": "Ft Riley bumblebees",
    "section": "",
    "text": "evaluate environmental factors affecting bumblebee density and abundance using distance sampling methods\n\n\n\n\n\n\n\nMultiple years of data, my approach\n\n\n\n\n\nThere are three years of survey data. The first year (2022) was described as a pilot survey, so I will not thoroughly examine the 2022 data."
  },
  {
    "objectID": "cassidy/lathrom.html#exploratory-data-analysis-for-2024",
    "href": "cassidy/lathrom.html#exploratory-data-analysis-for-2024",
    "title": "Ft Riley bumblebees",
    "section": "Exploratory data analysis for 2024",
    "text": "Exploratory data analysis for 2024\n\nlibrary(readxl)\nyr24 &lt;- read_xlsx(path=\"data/2022-2024_bee_ds_data.xlsx\", sheet = \"2024\")\n(numstrat &lt;- unique(yr24$Region.Label))\n\n[1] \"FRMR\"\n\n(numtrans &lt;- unique(yr24$Sample.Label))\n\n  [1]  61  63   6   5   4  84  74  65  31  12  11  88  87  86  91 105 109 106\n [19]  97  96  95  94 117 122 127 126 131  54 151 150 149 148  80  24  32  67\n [37]  64   8  57  56  55  90 110 112 115   3 113 114  89 140  82  81  79  77\n [55]  20  35   7   2  59  47  45  44  42  40  39  41  58 146 147 145 144  33\n [73] 123 124 125 128 130 116 118 119 120 121  52  53  68  69  70  62 103  66\n [91] 108  28  27  85  83  78  75  76   1  37  36 135 137 138 107  99 104  73\n[109]  72 132  71 134 143  60  25  23  26  30 136 139  22 102 100 101  51  50\n[127]  49  48 129   9  98  92  93  43  15\n\n(numspec &lt;- unique(yr24$species))\n\n [1] \"brown_belted\"    \"unk\"             \"carpenter\"       \"american\"       \n [5] \"twsp\"            \"AMER_BG\"         \"black_gold\"      \"southern_plains\"\n [9] \"eastern\"         \"bombus\"         \n\nt24 &lt;- table(yr24$species, yr24$sample.bout)\nknitr::kable(t24, caption=\"Approximate detections by species and bout for 2024\")\n\n\nApproximate detections by species and bout for 2024\n\n\n\n1\n2\n\n\n\n\nAMER_BG\n52\n33\n\n\namerican\n90\n108\n\n\nblack_gold\n23\n34\n\n\nbombus\n22\n5\n\n\nbrown_belted\n178\n197\n\n\ncarpenter\n198\n86\n\n\neastern\n28\n4\n\n\nsouthern_plains\n65\n52\n\n\ntwsp\n15\n0\n\n\nunk\n49\n14\n\n\n\n\n\nTwo things to note about the table above: - many detections for some species and - few detections for species I presume are rare (we’ll deal with that shortly).\n\n\n\n\n\n\nMy presumption about objectives\n\n\n\n\n\n\nI’m guessing Cassidy would like estimates by species and by sampling bout\nWe could easily ignore sampling bout and pool the data across bouts; this will produce density estimates that are the average density across the bouts.\nRather than pooling, I’ll take the more difficult analytical approach of producing species- and bout-specific density estimates.\n\n\n\n\nBefore starting the modelling, let’s come to grips with the distribution of perpendicular detection distances for species and bout combinations. This will give insight about what is in store for us when modelling begins.\nhistfn &lt;- function(frame, spec) {\n  hist(frame$distance[frame$species==spec & frame$sample.bout==1],\n       main=paste(spec, \" bout=May/June\"), xlab=\"Distance\", nc=20)\n  hist(frame$distance[frame$species==spec & frame$sample.bout==2],\n       main=paste(spec, \" bout=July/August\"), xlab=\"Distance\", nc=20)\n}\nhistfn(yr24, \"AMER_BG\")\nhistfn(yr24, \"american\")\nhistfn(yr24, \"black_gold\")\nhistfn(yr24, \"brown_belted\")\nhistfn(yr24, \"carpenter\")\nhistfn(yr24, \"southern_plains\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClearly there will be a struggle to fit detection function models to some of the species x bout combinations. Before we attack that problem, let’s tackle a simpler problem: estimating density for the common “brown_belted”."
  },
  {
    "objectID": "cassidy/lathrom.html#brown-belted-analysis",
    "href": "cassidy/lathrom.html#brown-belted-analysis",
    "title": "Ft Riley bumblebees",
    "section": "Brown belted analysis",
    "text": "Brown belted analysis\nThis species has nearly 200 detections for each sampling bout. Hence, if we wanted bout-specific estimates of density for this species, the most straightforward approach would be to simply pluck detections of brown_belted from the 2024 data frame.\n\nbb_bees_b1 &lt;- subset(yr24, species==\"brown_belted\" & sample.bout==1)\nbb_bees_b2 &lt;- subset(yr24, species==\"brown_belted\" & sample.bout==2)\n\nA quick check of the integrity of the survey design in the subsetted data shows:\n\nprint(length(unique(bb_bees_b1$Sample.Label)))\n\n[1] 53\n\nprint(length(unique(bb_bees_b2$Sample.Label)))\n\n[1] 45\n\n\nEven this most common species is only seen on little more than one-third of the 151 transects surveyed. If we carried on like this, we would produce extremely positively biased estimates of density.\nSolution, specify survey design manually using two arguments to the ds function: region_table and sample_table.\n\nbb_reg_tab1 &lt;- data.frame(Region.Label=\"FRMR\", Area=yr24$Area[1])\nbb_reg_tab2 &lt;- data.frame(Region.Label=\"FRMR\", Area=yr24$Area[1])\nbb_sam_tab1 &lt;- data.frame(Sample.Label=seq(1, 151),\n                         Region.Label=rep(\"FRMR\",151),\n                         Effort=rep(500,151))\nbb_sam_tab2 &lt;- data.frame(Sample.Label=seq(1, 151),\n                         Region.Label=rep(\"FRMR\",151),\n                         Effort=rep(500,151))"
  },
  {
    "objectID": "cassidy/testchild.html",
    "href": "cassidy/testchild.html",
    "title": "I am test child",
    "section": "",
    "text": "I am test child\n\nhist(runif(1000))"
  },
  {
    "objectID": "cassidy/lathrom.html#apply-function-to-the-selected-yr24_hr_2level-model",
    "href": "cassidy/lathrom.html#apply-function-to-the-selected-yr24_hr_2level-model",
    "title": "Ft Riley bumblebees",
    "section": "4.3 Apply function to the selected yr24_hr_2level model",
    "text": "4.3 Apply function to the selected yr24_hr_2level model\nCode below plucks out the relevant estimated coefficients from our model that included species and bout as covariates. I demonstrate only for two species and the two bouts. Code then plots the derived detection function from the fitted covariate coefficients. This gives us a sense check whether we’ve picked up the coefficients correctly.\n\ncoefs &lt;- yr24_hr_2level$ddf$par\nxmax &lt;- unname(yr24_hr_2level$ddf$meta.data$width)\nxvals &lt;- seq(0,xmax, length=100)\nam1 &lt;- gz(z=xvals, key=\"HR\",beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n          sigcoef = c(coefs[\"speciesamerican\"]))\nam2 &lt;- gz(z=xvals, key=\"HR\",beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n          sigcoef = c(coefs[\"speciesamerican\"], coefs[\"as.factor.sample.bout.2\"]))\nbomb1 &lt;- gz(z=xvals, key=\"HR\",beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n          sigcoef = c(coefs[\"speciesbombus\"]))\nbomb2 &lt;- gz(z=xvals, key=\"HR\",beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n          sigcoef = c(coefs[\"speciesbombus\"], coefs[\"as.factor.sample.bout.2\"]))\nplot(xvals, am1, lwd=2, type=\"l\",\n     main=\"Construct species x bout detection functions manually\",\n     xlab=\"Distance\", ylab=\"Detection probability\")\nlines(xvals, am2, lwd=2, col=\"blue\")\nlines(xvals, bomb1, lwd=2, col=\"darkgreen\")\nlines(xvals, bomb2, lwd=2, col=\"red\")\nlegend(\"topright\", legend=c(\"American1\", \"American2\", \"Bombus1\", \"Bombus2\"),\n       col=c(\"black\",\"blue\",\"darkgreen\",\"red\"), lwd=2)"
  },
  {
    "objectID": "cassidy/lathrom.html#integration-and-conversion-to-detection-probability",
    "href": "cassidy/lathrom.html#integration-and-conversion-to-detection-probability",
    "title": "Ft Riley bumblebees",
    "section": "4.4 Integration and conversion to detection probability",
    "text": "4.4 Integration and conversion to detection probability\nSense check completed, we now use our gz function to “manually” compute species- and bout-specific detection probabilities for the for examples created above. The formula being applied here (see Lecture 2 of notes) is \\(\\hat{P}_a\\) is “area under curve” divided by “area of rectangle”\n\\[\\hat{P}_a=\\frac{\\int^w_0 \\hat{g}(x) dx}{w} \\]\n\nam1_p_int &lt;- integrate(gz, lower=0, upper=xmax, key=\"HR\",\n                    beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n                    sigcoef = c(coefs[\"speciesamerican\"]))$value / xmax\nam2_p_int &lt;- integrate(gz, lower=0, upper=xmax, key=\"HR\",\n                    beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n                    sigcoef = c(coefs[\"speciesamerican\"], coefs[\"as.factor.sample.bout.2\"]))$value / xmax\nbomb1_p_int &lt;- integrate(gz, lower=0, upper=xmax, key=\"HR\",\n                    beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n                    sigcoef = c(coefs[\"speciesbombus\"]))$value / xmax\nbomb2_p_int &lt;- integrate(gz, lower=0, upper=xmax, key=\"HR\",\n                    beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n                    sigcoef = c(coefs[\"speciesbombus\"], coefs[\"as.factor.sample.bout.2\"]))$value / xmax"
  },
  {
    "objectID": "cassidy/lathrom.html#data-organisation-complete-fit-some-models",
    "href": "cassidy/lathrom.html#data-organisation-complete-fit-some-models",
    "title": "Ft Riley bumblebees",
    "section": "3.1 Data organisation complete, fit some models",
    "text": "3.1 Data organisation complete, fit some models\nA glance at the histograms produced earlier suggests an abrupt drop in detection probability around 5-8m, suggesting the flexibility of the hazard rate model will be useful, but we fit the full series of candidates to each bout. Note too the existence of a small number of detections at great distances, they will not be very useful in our detection function modelling. We are likely to be more aggressive in our truncation than we might otherwise be when dealing with non-insect species.\n\nlibrary(Distance)\ncu &lt;- convert_units(\"meter\", \"meter\", \"hectare\")\nbbunicos &lt;- ds(data=bb_bees_b1, key=\"unif\", adj=\"cos\", convert_units = cu,\n               region_table = bb_reg_tab1, sample_table = bb_sam_tab1,\n               truncation = \"10%\")\nbbhnherm &lt;- ds(data=bb_bees_b1, key=\"hn\", adj=\"herm\", convert_units = cu,\n               region_table = bb_reg_tab1, sample_table = bb_sam_tab1,\n               truncation = \"10%\")\nbbhrsim &lt;- ds(data=bb_bees_b1, key=\"hr\", adj=\"poly\", convert_units = cu,\n               region_table = bb_reg_tab1, sample_table = bb_sam_tab1,\n               truncation = \"10%\")\nknitr::kable(summarize_ds_models(bbunicos, bbhnherm, bbhrsim)[, c(2:7)],\n             digits=3, row.names=FALSE,\n             caption=\"Model criticism candidate model set\\n brown_belted bout 1\")\n\n\nModel criticism candidate model set brown_belted bout 1\n\n\n\n\n\n\n\n\n\n\nKey function\nFormula\nC-vM p-value\n\\(\\hat{P_a}\\)\nse(\\(\\hat{P_a}\\))\n\\(\\Delta\\)AIC\n\n\n\n\nUniform with cosine adjustment terms of order 1,2\nNA\n0.769\n0.446\n0.030\n0.000\n\n\nHazard-rate\n~1\n0.859\n0.444\n0.044\n0.312\n\n\nHalf-normal\n~1\n0.307\n0.477\n0.026\n0.831\n\n\n\n\n\nDouble-check that we have the right number of transects:\n\nknitr::kable(bbunicos$dht$individuals$summary)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegion\nArea\nCoveredArea\nEffort\nn\nk\nER\nse.ER\ncv.ER\n\n\n\n\nFRMR\n28383\n551.7512\n75500\n160\n151\n0.0021192\n0.0003848\n0.1815787\n\n\n\n\n\n\n\n\n\n\n\nWhat did we learn from this?\n\n\n\n\n\n\nall models fit the data\n\\(\\Delta\\)AIC among candidates is small\nNot by coincidence, \\(\\hat{P}_a\\) are very similar across models\n\n\n\n\nBefore examining the density estimate, continue for sampling bout 2\n\nlibrary(Distance)\ncu &lt;- convert_units(\"meter\", \"meter\", \"hectare\")\nbbunicos2 &lt;- ds(data=bb_bees_b2, key=\"unif\", adj=\"cos\", convert_units = cu,\n               region_table = bb_reg_tab2, sample_table = bb_sam_tab2,\n               truncation = \"10%\")\nbbhnherm2 &lt;- ds(data=bb_bees_b2, key=\"hn\", adj=\"herm\", convert_units = cu,\n               region_table = bb_reg_tab2, sample_table = bb_sam_tab2,\n               truncation = \"10%\")\nbbhrsim2 &lt;- ds(data=bb_bees_b2, key=\"hr\", adj=\"poly\", convert_units = cu,\n               region_table = bb_reg_tab2, sample_table = bb_sam_tab2,\n               truncation = \"10%\")\nknitr::kable(summarize_ds_models(bbunicos2, bbhnherm2, bbhrsim2)[, c(2:7)],\n             digits=3, row.names=FALSE,\n             caption=\"Model criticism candidate model set\\n brown_belted bout 2\")\n\n\nModel criticism candidate model set brown_belted bout 2\n\n\n\n\n\n\n\n\n\n\nKey function\nFormula\nC-vM p-value\n\\(\\hat{P_a}\\)\nse(\\(\\hat{P_a}\\))\n\\(\\Delta\\)AIC\n\n\n\n\nHazard-rate\n~1\n0.712\n0.236\n0.025\n0.000\n\n\nUniform with cosine adjustment terms of order 1,2,3,4,5\nNA\n0.643\n0.227\n0.016\n5.307\n\n\nHalf-normal\n~1\n0.000\n0.358\n0.014\n42.282\n\n\n\n\n\nThe difference in \\(\\Delta\\)AIC among candidates is greater for bout 2, and you will see a bit more disparity between \\(\\hat{P}_a\\), particularly the non-fitting half normal model.\nLet’s look at the fit of the selected models for each bout:\nplot(bbunicos, nc=20, main=\"brown_belted, bout 1, unifcos\")\nplot(bbhrsim2, nc=20, main=\"brown_belted, bout 2, hazard rate\")\n\n\n\n\n\n\n\n\n\n\nLooking at the plots, I think I would truncate yet more aggressively again; to ~30m.\n\nbbunicosx &lt;- ds(data=bb_bees_b1, key=\"unif\", adj=\"cos\", convert_units = cu,\n               region_table = bb_reg_tab1, sample_table = bb_sam_tab1,\n               truncation = 31)\nbbhnhermx &lt;- ds(data=bb_bees_b1, key=\"hn\", adj=\"herm\", convert_units = cu,\n               region_table = bb_reg_tab1, sample_table = bb_sam_tab1,\n               truncation = 31)\nbbhrsimx &lt;- ds(data=bb_bees_b1, key=\"hr\", adj=\"poly\", convert_units = cu,\n               region_table = bb_reg_tab1, sample_table = bb_sam_tab1,\n               truncation = 31)\nbbunicos2x &lt;- ds(data=bb_bees_b2, key=\"unif\", adj=\"cos\", convert_units = cu,\n               region_table = bb_reg_tab2, sample_table = bb_sam_tab2,\n               truncation = 31)\nbbhnherm2x &lt;- ds(data=bb_bees_b2, key=\"hn\", adj=\"herm\", convert_units = cu,\n               region_table = bb_reg_tab2, sample_table = bb_sam_tab2,\n               truncation = 31)\nbbhrsim2x &lt;- ds(data=bb_bees_b2, key=\"hr\", adj=\"poly\", convert_units = cu,\n               region_table = bb_reg_tab2, sample_table = bb_sam_tab2,\n               truncation = 31)\nknitr::kable(summarize_ds_models(bbunicosx, bbhnhermx, bbhrsimx)[, c(2:7)],\n             digits=3, row.names=FALSE,\n             caption=\"Model criticism candidate model set\\n brown_belted bout 1 trunc=31\")\n\n\nModel criticism candidate model set brown_belted bout 1 trunc=31\n\n\n\n\n\n\n\n\n\n\nKey function\nFormula\nC-vM p-value\n\\(\\hat{P_a}\\)\nse(\\(\\hat{P_a}\\))\n\\(\\Delta\\)AIC\n\n\n\n\nUniform with cosine adjustment terms of order 1,2\nNA\n0.929\n0.487\n0.039\n0.000\n\n\nHalf-normal\n~1\n0.470\n0.532\n0.032\n0.277\n\n\nHazard-rate\n~1\n0.900\n0.495\n0.054\n0.609\n\n\n\n\nknitr::kable(summarize_ds_models(bbunicos2x, bbhnherm2x, bbhrsim2x)[, c(2:7)],\n             digits=3, row.names=FALSE,\n             caption=\"Model criticism candidate model set\\n brown_belted bout 2 trunc=31\")\n\n\nModel criticism candidate model set brown_belted bout 2 trunc=31\n\n\n\n\n\n\n\n\n\n\nKey function\nFormula\nC-vM p-value\n\\(\\hat{P_a}\\)\nse(\\(\\hat{P_a}\\))\n\\(\\Delta\\)AIC\n\n\n\n\nHazard-rate\n~1\n0.691\n0.431\n0.044\n0.000\n\n\nUniform with cosine adjustment terms of order 1,2,3\nNA\n0.358\n0.375\n0.032\n2.995\n\n\nHalf-normal\n~1\n0.093\n0.473\n0.025\n7.611\n\n\n\n\n\nplot(bbunicosx, nc=20, main=\"brown_belted, bout 1, unifcos, trunc=31\")\nplot(bbhrsim2x, nc=20, main=\"brown_belted, bout 2, hazard rate, trunc=31\")"
  },
  {
    "objectID": "cassidy/lathrom.html#did-truncation-changes-influence-estimated-density",
    "href": "cassidy/lathrom.html#did-truncation-changes-influence-estimated-density",
    "title": "Ft Riley bumblebees",
    "section": "3.2 Did truncation changes influence estimated density?",
    "text": "3.2 Did truncation changes influence estimated density?\nWe have seen there is no change in the models selected when changing the truncation distance, how about the estimates?\n\nbb1_10 &lt;- bbunicos$dht$individuals$D\nbb2_10 &lt;- bbhrsim$dht$individuals$D\nbb1_31 &lt;- bbunicosx$dht$individuals$D\nbb2_31 &lt;- bbhrsimx$dht$individuals$D\nestimates &lt;- rbind(bb1_10, bb1_31, bb2_10, bb2_31)\nestimates$Label &lt;- c(\"Bout1 10%\", \"Bout1 31m\", \"Bout2 10%\", \"Bout2 31m\")\nknitr::kable(estimates, digits=3,\n             caption=\"Estimates for brown belted, both bouts, different truncation distances\")\n\n\nEstimates for brown belted, both bouts, different truncation distances\n\n\nLabel\nEstimate\nse\ncv\nlcl\nucl\ndf\n\n\n\n\nBout1 10%\n0.651\n0.126\n0.193\n0.446\n0.950\n190.066\n\n\nBout1 31m\n0.684\n0.138\n0.201\n0.462\n1.013\n203.897\n\n\nBout2 10%\n0.653\n0.135\n0.206\n0.436\n0.976\n231.548\n\n\nBout2 31m\n0.673\n0.144\n0.214\n0.443\n1.022\n243.124\n\n\n\n\n\nWe see roughly a 3-5% difference in the point estimates from the more aggressive truncation. Place that difference in the context of the coefficient of variation (~20%).\n\nWe could continue to carry out this species by species, bout by bout analysis for the common species. However, eventually problems will arise when get to species like AMER_BG, black_gold, bombus, etc. If estimates for those species x bout combinations are important, we will have to “borrow strength” from other species to produce robust estimates for those rare species.\nWe “borrow strength” via the use of species and sampling bout as covariates in the detection function. I ignore other potential covariates, e.g. observer, because the property of pooling robustness ensures that bias is not introduced by ignoring such covariates."
  },
  {
    "objectID": "cassidy/lathrom.html#sec-brownbelt",
    "href": "cassidy/lathrom.html#sec-brownbelt",
    "title": "Ft Riley bumblebees",
    "section": "Brown belted analysis",
    "text": "Brown belted analysis\nThis species has nearly 200 detections for each sampling bout. Hence, if we wanted bout-specific estimates of density for this species, the most straightforward approach would be to simply pluck detections of brown_belted from the 2024 data frame.\n\nbb_bees_b1 &lt;- subset(yr24, species==\"brown_belted\" & sample.bout==1)\nbb_bees_b2 &lt;- subset(yr24, species==\"brown_belted\" & sample.bout==2)\n\nA quick check of the integrity of the survey design in the subsetted data shows:\n\nprint(length(unique(bb_bees_b1$Sample.Label)))\n\n[1] 53\n\nprint(length(unique(bb_bees_b2$Sample.Label)))\n\n[1] 45\n\n\nEven this most common species is only seen on little more than one-third of the 151 transects surveyed. If we carried on like this, we would produce extremely positively biased estimates of density.\nSolution, specify survey design manually using two arguments to the ds function: region_table and sample_table.\n\nbb_reg_tab1 &lt;- data.frame(Region.Label=\"FRMR\", Area=yr24$Area[1])\nbb_reg_tab2 &lt;- data.frame(Region.Label=\"FRMR\", Area=yr24$Area[1])\nbb_sam_tab1 &lt;- data.frame(Sample.Label=seq(1, 151),\n                         Region.Label=rep(\"FRMR\",151),\n                         Effort=rep(500,151))\nbb_sam_tab2 &lt;- data.frame(Sample.Label=seq(1, 151),\n                         Region.Label=rep(\"FRMR\",151),\n                         Effort=rep(500,151))"
  },
  {
    "objectID": "cassidy/lathrom.html#compare-estimates-from-basic-analysis",
    "href": "cassidy/lathrom.html#compare-estimates-from-basic-analysis",
    "title": "Ft Riley bumblebees",
    "section": "5.1 Compare estimates from “basic” analysis",
    "text": "5.1 Compare estimates from “basic” analysis\nRemember we started the modelling of the 2024 data by looking at the “brown_belted” species in Section Section 3. In that analysis, each sampling bout for that species was modelled in isolation, as there were sufficient numbers of detections of that species in each bout.\nAfter choosing the most appropriate models from that pair of analyses, density estimates were\n\nknitr::kable(estimates[c(1,3),], digits=2, caption=\"Estimated brown belted densities from 'standalone' analysis\")\n\n\nEstimated brown belted densities from ‘standalone’ analysis\n\n\n\nLabel\nEstimate\nse\ncv\nlcl\nucl\ndf\n\n\n\n\n1\nBout1 10%\n0.65\n0.13\n0.19\n0.45\n0.95\n190.07\n\n\n3\nBout2 10%\n0.65\n0.13\n0.21\n0.44\n0.98\n231.55\n\n\n\n\n\nCompare these point and interval estimates to those generated from our 2-level stratification model:\n\nbb1cov &lt;- yr24_hr_2level$dht$individuals$D[yr24_hr_2level$dht$individuals$D$Label==\"brown_belted1\", ]\nbb2cov &lt;- yr24_hr_2level$dht$individuals$D[yr24_hr_2level$dht$individuals$D$Label==\"brown_belted2\", ]\nknitr::kable(rbind(bb1cov, bb2cov)[,1:6], digits=3,\n             caption=\"Density estimates brown belted from HR covariate model\")\n\n\nDensity estimates brown belted from HR covariate model\n\n\n\nLabel\nEstimate\nse\ncv\nlcl\nucl\n\n\n\n\n9\nbrown_belted1\n0.676\n0.134\n0.198\n0.459\n0.995\n\n\n10\nbrown_belted2\n0.805\n0.167\n0.208\n0.537\n1.207\n\n\n\n\n\nThere is some difference in the point estimate for sampling bout 2; however the confidence intervals for the estimates from the two modelling approaches are quite similar. With reasonable data, which these are, the estimates are often robust to decisions made during analysis."
  },
  {
    "objectID": "cassidy/lathrom.html#given-the-preferred-model-is-ok-look-at-the-plot",
    "href": "cassidy/lathrom.html#given-the-preferred-model-is-ok-look-at-the-plot",
    "title": "Ft Riley bumblebees",
    "section": "4.2 Given the preferred model is OK, look at the plot",
    "text": "4.2 Given the preferred model is OK, look at the plot\n\nplot(yr24_hr_2level, nc=39)\nsp &lt;- unique(yr24$species)\nbo &lt;- unique(yr24$sample.bout)\npalette(\"ggplot2\")\nfor (i in 1:length(sp)) {\n  for (j in 1:length(bo))\n  add_df_covar_line(yr24_hr_2level, \n                    data=data.frame(species=sp[i], sample.bout=bo[j]),\n                    lwd=2, lty=1, col=rainbow(19)[i])\n}\nlegend(\"topright\", title=\"Spec x bout\", legend=unique(yr24$Region.Label),\n       lwd=2, lty=1, col=rainbow(19), cex=0.8)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpecies and bout-specific detection probability estimates\n\n\n\n\n\nAlthough the figure is pretty, we cannot deduce the species x bout-specific detection probabilities. Assuming these estimates are of interest, how do we produce them, given the software won’t cooperate with our request. Answer integrate detection function over distance for specific covariate levels.\n\n\n\nBelow is a function that will calculate detection probability for a given set of estimated covariate coefficients at a given perpendicular distance. We will use the function, in conjunction with the coefficients for a species and bout combination of interest.\n\ngz&lt;-function(z,\n             beta, sigintercept, sigcoef, DistWin=FALSE,\n             key=\"HR\", w=max(z)){\n#this is a generic detection function that returns the probability of detecting an animal\n#    z               generic distance (perpendicular) - can be scalar or vector\n#    beta            shape coefficient\n#    sigintercept  intercept coefficient for sigma\n#    sigcoef         coefficient for specific factor level\n#    DistWin         coefficients from Distance for Windows or from R\n#    key             the detection function key, works for hazard rate and half normal\n#    w               truncation distance, by default the max of the distances\n#\n#RETURNS: a probability\n  \n  if(key != \"HN\" & key != \"HR\") {\n    stop(\"Argument 'key' must be either HN or HR\")\n  }\n  if (DistWin) {\n    sigma &lt;- sigintercept + exp(sigcoef)\n    exponent &lt;- beta\n  } else {\n    numterms &lt;- length(sigcoef)\n    predictor &lt;- 0\n    for (i in 1:numterms) {\n      predictor &lt;- predictor + sigcoef[i]\n    }\n    sigma &lt;- exp(sigintercept + predictor)\n    exponent &lt;- exp(beta)\n  }\n  if(key==\"HR\") {\n    scale.dist &lt;- z/sigma\n    inside &lt;- -(scale.dist)^(-exponent)\n    gx &lt;- 1 - exp(inside)\n  } else {\n    scale.dist &lt;- z  # debatably don't scale for half normal\n    inside &lt;- -(scale.dist^2/(2*sigma^2))\n    gx &lt;- exp(inside)\n  }\n  return(gx)\n}"
  },
  {
    "objectID": "cassidy/lathrom.html#magical-estimates-for-rare-species",
    "href": "cassidy/lathrom.html#magical-estimates-for-rare-species",
    "title": "Ft Riley bumblebees",
    "section": "6.1 Magical estimates for rare species?",
    "text": "6.1 Magical estimates for rare species?\nDensity estimates are produced for all species in the data frame Table 1; even for species with as few as four detections (eastern2). Is that some kind of magic? No, look closely at the measures of precision associated with the species with small numbers of detection:\n\nlibrary(kableExtra)\nknitr::kable(table.attr=\"quarto-disable-processing=true\",\n             format=\"html\",\n             yr24_hr_2level$dht$individuals$D[, 1:6],\n             row.names = FALSE, digits=3) %&gt;%\n  row_spec(c(5:8,13:14,17), background = \"salmon\") %&gt;%\n  row_spec(c(18:20), strikeout=TRUE) %&gt;%\n  column_spec(c(2:6), width=\"4em\")\n\n\n \n  \n    Label \n    Estimate \n    se \n    cv \n    lcl \n    ucl \n  \n \n\n  \n    AMER_BG1 \n    0.193 \n    0.046 \n    0.237 \n    0.122 \n    0.306 \n  \n  \n    AMER_BG2 \n    0.164 \n    0.047 \n    0.286 \n    0.095 \n    0.286 \n  \n  \n    american1 \n    0.369 \n    0.071 \n    0.191 \n    0.254 \n    0.536 \n  \n  \n    american2 \n    0.556 \n    0.123 \n    0.221 \n    0.361 \n    0.854 \n  \n  \n    black_gold1 \n    0.070 \n    0.024 \n    0.342 \n    0.037 \n    0.135 \n  \n  \n    black_gold2 \n    0.112 \n    0.038 \n    0.337 \n    0.059 \n    0.213 \n  \n  \n    bombus1 \n    0.065 \n    0.024 \n    0.374 \n    0.032 \n    0.132 \n  \n  \n    bombus2 \n    0.020 \n    0.010 \n    0.517 \n    0.008 \n    0.052 \n  \n  \n    brown_belted1 \n    0.676 \n    0.134 \n    0.198 \n    0.459 \n    0.995 \n  \n  \n    brown_belted2 \n    0.805 \n    0.167 \n    0.208 \n    0.537 \n    1.207 \n  \n  \n    carpenter1 \n    1.126 \n    0.175 \n    0.155 \n    0.831 \n    1.525 \n  \n  \n    carpenter2 \n    0.551 \n    0.108 \n    0.196 \n    0.376 \n    0.808 \n  \n  \n    eastern1 \n    0.109 \n    0.039 \n    0.358 \n    0.055 \n    0.215 \n  \n  \n    eastern2 \n    0.010 \n    0.008 \n    0.748 \n    0.003 \n    0.038 \n  \n  \n    southern_plains1 \n    0.230 \n    0.058 \n    0.252 \n    0.141 \n    0.375 \n  \n  \n    southern_plains2 \n    0.196 \n    0.063 \n    0.321 \n    0.106 \n    0.363 \n  \n  \n    twsp1 \n    0.060 \n    0.032 \n    0.532 \n    0.022 \n    0.160 \n  \n  \n    unk1 \n    0.300 \n    0.073 \n    0.244 \n    0.187 \n    0.482 \n  \n  \n    unk2 \n    0.107 \n    0.035 \n    0.327 \n    0.057 \n    0.201 \n  \n  \n    Total \n    0.301 \n    0.021 \n    0.070 \n    0.263 \n    0.345 \n  \n\n\n\n\n\nEven though density estimates were produces for these species x bout combinations, their precision would suggest the estimates are not terribly reliable. It is comforting that the imprecision of these estimates is consistent with the small number of detections, even if there is some “borrowing of strength” from other species. This use of covariates may help in the modelling of the detection function, but remember the role that encounter rates and their variability plays in density estimation."
  }
]