[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kansas State workshop",
    "section": "",
    "text": "Distance sampling of several data sets\nThese are not intended to be complete analyses, but rather the initial steps in a thorough analysis of such data."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "rachel/rusten.html",
    "href": "rachel/rusten.html",
    "title": "Sandhills Grassland Birds",
    "section": "",
    "text": "Goal: Evaluate the effects of Eastern Redcedar removal treatments and management on avian communities in eastern Sandhills Ecoregion in Nebraska, USA\n\n\n\n\n\n\n\n\n\n\nBefore beginning, a note about point transects\n\n\n\n\n\n\nAnimal movement can bias distance sampling estimates\nBias is magnified when animals move faster than observers\nObservers are stationary during point counts\nSee Buckland (2006) regarding “snapshot moment” to alleviate bias"
  },
  {
    "objectID": "rachel/rusten.html#are-grassland-restoration-actions-of-woody-removal-benefiting-local-native-wildlife",
    "href": "rachel/rusten.html#are-grassland-restoration-actions-of-woody-removal-benefiting-local-native-wildlife",
    "title": "Sandhills Grassland Birds",
    "section": "",
    "text": "Goal: Evaluate the effects of Eastern Redcedar removal treatments and management on avian communities in eastern Sandhills Ecoregion in Nebraska, USA\n\n\n\n\n\n\n\n\n\n\nBefore beginning, a note about point transects\n\n\n\n\n\n\nAnimal movement can bias distance sampling estimates\nBias is magnified when animals move faster than observers\nObservers are stationary during point counts\nSee Buckland (2006) regarding “snapshot moment” to alleviate bias"
  },
  {
    "objectID": "cassidy/lathrom.html",
    "href": "cassidy/lathrom.html",
    "title": "Ft Riley bumblebees",
    "section": "",
    "text": "evaluate environmental factors affecting bumblebee density and abundance using distance sampling methods\n\n\n\n\n\n\n\nMultiple years of data, my approach\n\n\n\n\n\nThere are three years of survey data. The first year (2022) was described as a pilot survey, so I will not thoroughly examine the 2022 data."
  },
  {
    "objectID": "cassidy/lathrom.html#status-of-native-bumblebees-bombus-spp.-at-fort-riley-military-reservation-kansas",
    "href": "cassidy/lathrom.html#status-of-native-bumblebees-bombus-spp.-at-fort-riley-military-reservation-kansas",
    "title": "Ft Riley bumblebees",
    "section": "",
    "text": "evaluate environmental factors affecting bumblebee density and abundance using distance sampling methods"
  },
  {
    "objectID": "rachel/rusten.html#becoming-acquainted-with-data",
    "href": "rachel/rusten.html#becoming-acquainted-with-data",
    "title": "Sandhills Grassland Birds",
    "section": "2 Becoming acquainted with data",
    "text": "2 Becoming acquainted with data\n\nalldata &lt;- read.csv(file=\"data/Rusten_GrasslandBird_dist24.csv\")\n(numstrat &lt;- unique(alldata$Region.Label))\n\n [1] \"BLA049-C\"    \"Dismal E\"    \"Double E\"    \"Double M\"    \"Double W\"   \n [6] \"GAR-LOWja\"   \"GAR-ML-A\"    \"GAR-PLU\"     \"GAR-WIL-A\"   \"GAR-WIL-B\"  \n[11] \"GAR-WIL-C\"   \"GAR041-B\"    \"GAR045-A\"    \"GAR045-B\"    \"GAR046-A\"   \n[16] \"GAR046-B\"    \"GAR046-C\"    \"GAR046-H\"    \"GAR046-M\"    \"GAR053-A\"   \n[21] \"GAR053-B\"    \"GAR054\"      \"LOU-SMI-A\"   \"LOU-SMI-B\"   \"LOU-SMI-C\"  \n[26] \"LOU-SWMB\"    \"Valentine A\" \"Valentine B\" \"Weggener\"    \"WHE014\"     \n[31] \"WHE035-A\"    \"WHE035-B\"    \"WHE035-C\"   \n\n(numspec &lt;- unique(alldata$Species))\n\n [1] \"WEME\"  \"GRSP\"  NA      \"NOFL\"  \"WITU\"  \"BHCO\"  \"MODO\"  \"LASP\"  \"FISP\" \n[10] \"BLGR\"  \"CONI\"  \"AMCR\"  \"KILL\"  \"BARS\"  \"HOLA\"  \"RTHA\"  \"RHWO\"  \"AGOL\" \n[19] \"AMRO\"  \"BLJA\"  \"SPTO\"  \"NOCA\"  \"DICK\"  \"CLSW\"  \"UPSA\"  \"LBCO\"  \"NOBO\" \n[28] \"WEKI\"  \"BEVI\"  \"RWBL\"  \"HOWR\"  \"EAKI\"  \"GRCA\"  \"BRTH\"  \"CHSP\"  \"SOSP\" \n[37] \"OROR\"  \"NODO\"  \"YEWA\"  \"BAOR\"  \"COGR\"  \"MALL\"  \"BOBO\"  \"MODI\"  \"AMCK\" \n[46] \"MAKE\"  \"HCWR\"  \"NOFC\"  \"WISN\"  \"BWTE\"  \"YHBL\"  \"MAWR\"  \"NOPI\"  \"EUST\" \n[55] \"COYE\"  \"WIPH\"  \"AMBI\"  \"SORA\"  \"AMKE\"  \"LOSH\"  \"TRES\"  \"EUCD\"  \"YBCH\" \n[64] \"GTGR\"  \"WAVI\"  \"COHA\"  \"STGR\"  \"TUVU\"  \"UNSP\"  \"RWRL\"  \"REVI\"  \"SPTP\" \n[73] \"RNEP\"  \"EATO\"  \"BBHCO\" \"BBCH\"  \"NRWS\"  \"CANG\"  \"VESP\"  \"GRPC\"  \"WODU\" \n[82] \"RINP\"  \"AWPE\"  \"SWSP\"  \"BCOH\"  \"BAEA\"  \"CEWA\"  \"LBCU\"  \"GCFL\"  \"INBU\" \n[91] \"SWHA\" \n\n\nGoodness, there are 91 species recorded during the 2024 field season. Let’s focus attention upon four species of interest: GRSP, WEME, DICK, UPSA:\n\nfourspec &lt;- subset(alldata, subset = Species %in% c(\"GRSP\", \"WEME\", \"DICK\", \"UPSA\"))\ntable(fourspec$Region.Label, fourspec$Species)\n\n             \n              DICK GRSP UPSA WEME\n  BLA049-C       0   34    0   47\n  Dismal E      29   47    1   48\n  Double E       8   22   10   55\n  Double M       2   66    0   42\n  Double W      28   49    0   24\n  GAR-LOWja     17   15    1    5\n  GAR-ML-A      32   32    1   31\n  GAR-PLU       31   24    0   25\n  GAR-WIL-A     21   14    6   21\n  GAR-WIL-B     13   33    0   30\n  GAR-WIL-C     26   54    0   38\n  GAR041-B      31   26    0   21\n  GAR045-A       1   43    4   30\n  GAR045-B       0   75    8   51\n  GAR046-A      15   34    2   21\n  GAR046-B      22   21    0   21\n  GAR046-C      45   48    2   47\n  GAR046-H      41   51   10   36\n  GAR046-M      10   44    3   38\n  GAR053-A      36   54    1   36\n  GAR053-B      43   36    1   33\n  GAR054        50   56    2   38\n  LOU-SMI-A      7   41    3   34\n  LOU-SMI-B     34   59    5   51\n  LOU-SMI-C     18   43    3   29\n  LOU-SWMB      52   42    0   27\n  Valentine A    9   17    4   17\n  Valentine B   19   12    5   20\n  Weggener       0   45    2   47\n  WHE014        26   28    1   37\n  WHE035-A      17   22    0   18\n  WHE035-B      44   58    0   49\n  WHE035-C      36   21    0   30\n\n\nDetections by Region.Label may be a bit sparse, particularly for UPSA. Let’s see how number of detections changes if we aggregate at the level of Group.\n\ntable(fourspec$Group, fourspec$Species)\n\n           \n            DICK GRSP UPSA WEME\n  BLA049       0   34    0   47\n  FS          67  229   13  216\n  GAR-LOW     17   15    1    5\n  GAR-ML      32   32    1   31\n  GAR-WIL     60  101    6   89\n  GAR041      31   26    0   21\n  GAR045       1  118   12   81\n  GAR046     133  198   17  163\n  GAR053      79   90    2   69\n  GAR054      50   56    2   38\n  GARPLU      31   24    0   25\n  LOU-SMI     59  143   11  114\n  LOU-SW      52   42    0   27\n  Valentine   28   29    9   37\n  WHE014      26   28    1   37\n  WHE035      97  101    0   97\n\n\nThat is an improvement.\n\n2.1 Transects within Region.Label or Group\nI’m unsure about the naming scheme for points stations. It seems most sensible for transects to “belong” to strata, but the numbering system does not seem to follow that. Perhaps using GridPointID as Sample.Label makes more sense? In most instances, it seems there are 12 replicate GridPointID values.\n\nunique(fourspec$GridPointID[fourspec$Region.Label==\"Double W\"])\n\n [1] \"Double W-194\" \"Double W-21\"  \"Double W-247\" \"Double W-372\" \"Double W-385\"\n [6] \"Double W-427\" \"Double W-478\" \"Double W-529\" \"Double W-610\" \"Double W-764\"\n[11] \"Double W-851\" \"Double W-904\"\n\n\nI’ll modify the working data frame to make GridPointID the point transect identified Sample.Label.\n\nfourspec$Sample.Label &lt;- fourspec$GridPointID\n\n\n\n2.2 Birds in flocks\nIs this of significance?\n\ntable(fourspec$Species, fourspec$Flock)\n\n      \n          1    2    3    4    5\n  DICK  746   13    4    0    0\n  GRSP 1248   14    2    1    1\n  UPSA   72    2    1    0    0\n  WEME 1075   13    8    1    0\n\n\nOnly 2.2% of dickcissel detections were of flocks &gt;1 individual, which is unlikely to alter the abundance/density estimates noticeably.\nWe will see if that makes a difference."
  },
  {
    "objectID": "rachel/rusten.html#exploratory-data-analysis-of-detection-distances",
    "href": "rachel/rusten.html#exploratory-data-analysis-of-detection-distances",
    "title": "Sandhills Grassland Birds",
    "section": "3 Exploratory data analysis of detection distances",
    "text": "3 Exploratory data analysis of detection distances\n\n\n\n\n\n\nDistances recorded as -1\n\n\n\n\n\nDon’t know why they exist, but they mess with detection function fitting, I’m throwing them out\n\n\n\n\nfourspec &lt;- subset(fourspec, subset = distance&gt; -1)\n\nhist(fourspec$distance[fourspec$Species==\"GRSP\"], \n     main=\"GRSP\", xlab=\"Radial distance\", nc=40)\nhist(fourspec$distance[fourspec$Species==\"WEME\"], \n     main=\"WEME\", xlab=\"Radial distance\", nc=40)\nhist(fourspec$distance[fourspec$Species==\"DICK\"], \n     main=\"DICK\", xlab=\"Radial distance\", nc=40)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProbably rounding of distances for meadowlark around 200 and 300m, but that shouldn’t cause problems."
  },
  {
    "objectID": "rachel/rusten.html#simple-analysis-for-estimates-at-the-group-level",
    "href": "rachel/rusten.html#simple-analysis-for-estimates-at-the-group-level",
    "title": "Sandhills Grassland Birds",
    "section": "4 Simple analysis for estimates at the Group level",
    "text": "4 Simple analysis for estimates at the Group level\nStandard practice will be to remove 10% most distant detections.\n\nlibrary(Distance)\n\nLoading required package: mrds\n\n\nThis is mrds 3.0.0\nBuilt: R 4.4.1; ; 2024-10-23 19:10:34 UTC; windows\n\n\n\nAttaching package: 'Distance'\n\n\nThe following object is masked from 'package:mrds':\n\n    create.bins\n\ncu &lt;- convert_units(\"meter\", NULL, \"hectare\")\nweme &lt;- subset(fourspec, Species==\"WEME\")\nweme.hn &lt;- ds(data=weme, transect = \"point\",\n         key=\"hn\", truncation = \"10%\",  convert_units = cu, adjustment = \"herm\")\n\nStarting AIC adjustment term selection.\n\n\nFitting half-normal key function\n\n\nAIC= 10176.094\n\n\nFitting half-normal key function with Hermite(4) adjustments\n\n\nAIC= 10167.679\n\n\nFitting half-normal key function with Hermite(4,6) adjustments\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis greater than 1 at some distances\n\n\nAIC= 10169.671\n\n\n\nHalf-normal key function with Hermite(4) adjustments selected.\n\nweme.uncos &lt;- ds(data=weme, transect = \"point\",\n         key=\"unif\", truncation = \"10%\",  convert_units = cu)\n\nStarting AIC adjustment term selection.\n\n\nFitting uniform key function\n\n\nAIC= 10752.837\n\n\nFitting uniform key function with cosine(1) adjustments\n\n\nAIC= 10162.97\n\n\nFitting uniform key function with cosine(1,2) adjustments\n\n\nAIC= 10164.74\n\n\n\nUniform key function with cosine(1) adjustments selected.\n\nweme.hr &lt;- ds(data=weme, transect = \"point\",\n         key=\"hr\", truncation = \"10%\",  convert_units = cu, adjustment = \"poly\")\n\nStarting AIC adjustment term selection.\n\n\nFitting hazard-rate key function\n\n\nAIC= 10125.116\n\n\nFitting hazard-rate key function with simple polynomial(4) adjustments\n\n\nAIC= 10127.116\n\n\n\nHazard-rate key function selected.\n\nsummarize_ds_models(weme.hn, weme.uncos, weme.hr)\n\n                 Model\n3    \\\\texttt{weme.hr}\n2 \\\\texttt{weme.uncos}\n1    \\\\texttt{weme.hn}\n                                                    Key function Formula\n3                                                    Hazard-rate      ~1\n2                 Uniform with cosine adjustment term of order 1    &lt;NA&gt;\n1 Half-normal with Hermite polynomial adjustment term of order 4      ~1\n  C-vM p-value $\\\\hat{P_a}$ se($\\\\hat{P_a}$) $\\\\Delta$AIC\n3 0.0446337078    0.4130381      0.017163665      0.00000\n2 0.0004631091    0.3490043      0.006997644     37.85355\n1 0.0028774891    0.4031840      0.043259167     42.56221\n\nplot(weme.hr, pdf=TRUE, nc=40, main=\"WEME, HR, pooled detfn\")\n\n\n\n\n\n\n\n\n\ncu &lt;- convert_units(\"meter\", NULL, \"hectare\")\ndick &lt;- fourspec[fourspec$Species==\"DICK\",]\ndick.hn &lt;- ds(data=dick, transect = \"point\",\n         key=\"hn\", truncation = \"10%\",  convert_units = cu, adjustment = \"herm\")\n\nStarting AIC adjustment term selection.\n\n\nFitting half-normal key function\n\n\nAIC= 6761.816\n\n\nFitting half-normal key function with Hermite(4) adjustments\n\n\nAIC= 6734.482\n\n\nFitting half-normal key function with Hermite(4,6) adjustments\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis greater than 1 at some distances\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis greater than 1 at some distances\n\n\nAIC= 6735.127\n\n\n\nHalf-normal key function with Hermite(4) adjustments selected.\n\ndick.uncos &lt;- ds(data=dick, transect = \"point\",\n         key=\"unif\", truncation = \"10%\",  convert_units = cu)\n\nStarting AIC adjustment term selection.\n\n\nFitting uniform key function\n\n\nAIC= 7054.786\n\n\nFitting uniform key function with cosine(1) adjustments\n\n\nAIC= 6755.077\n\n\nFitting uniform key function with cosine(1,2) adjustments\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis greater than 1 at some distances\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis greater than 1 at some distances\n\n\nAIC= 6725.678\n\n\nFitting uniform key function with cosine(1,2,3) adjustments\n\n\n** Warning: Maximum probability of detection is greater than one: invalid model fitted **\n** Warning: Maximum probability of detection is greater than one: invalid model fitted **\n** Warning: Maximum probability of detection is greater than one: invalid model fitted **\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis not weakly monotonic!\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis not strictly monotonic!\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis greater than 1 at some distances\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis not weakly monotonic!\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis not strictly monotonic!\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis greater than 1 at some distances\n\n\nAIC= 6723.171\n\n\nFitting uniform key function with cosine(1,2,3,4) adjustments\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis not strictly monotonic!\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis not strictly monotonic!\n\n\nAIC= 6715.747\n\n\nFitting uniform key function with cosine(1,2,3,4,5) adjustments\n\n\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis not strictly monotonic!\nWarning in check.mono(result, n.pts = control$mono.points): Detection function\nis not strictly monotonic!\n\n\nAIC= 6716.003\n\n\n\nUniform key function with cosine(1,2,3,4) adjustments selected.\n\n\nWarning in mrds::check.mono(model, n.pts = 10): Detection function is not\nstrictly monotonic!\n\ndick.hr &lt;- ds(data=dick, transect = \"point\",\n         key=\"hr\", truncation = \"10%\",  convert_units = cu, adjustment = \"poly\")\n\nStarting AIC adjustment term selection.\n\n\nFitting hazard-rate key function\n\n\nAIC= 6708.399\n\n\nFitting hazard-rate key function with simple polynomial(4) adjustments\n\n\nAIC= 6710.399\n\n\n\nHazard-rate key function selected.\n\nsummarize_ds_models(dick.hn, dick.uncos, dick.hr)\n\n                 Model\n3    \\\\texttt{dick.hr}\n2 \\\\texttt{dick.uncos}\n1    \\\\texttt{dick.hn}\n                                                    Key function Formula\n3                                                    Hazard-rate      ~1\n2          Uniform with cosine adjustment terms of order 1,2,3,4    &lt;NA&gt;\n1 Half-normal with Hermite polynomial adjustment term of order 4      ~1\n  C-vM p-value $\\\\hat{P_a}$ se($\\\\hat{P_a}$) $\\\\Delta$AIC\n3  0.030839941    0.5151049       0.02079957      0.00000\n2  0.008889366    0.4895714       0.11422470      7.34863\n1  0.000541476    0.4498981       0.06111644     26.08327\n\nplot(dick.hr, pdf=TRUE, nc=40, main=\"DICK, HR, pooled detfn\")\n\n\n\n\n\n\n\n\n\ncu &lt;- convert_units(\"meter\", NULL, \"hectare\")\ngrsp &lt;- fourspec[fourspec$Species==\"GRSP\",]\ngrsp.hn &lt;- ds(data=grsp, transect = \"point\",\n         key=\"hn\", truncation = \"10%\",  convert_units = cu, adjustment = \"herm\")\n\nStarting AIC adjustment term selection.\n\n\nFitting half-normal key function\n\n\nAIC= 10188.996\n\n\nFitting half-normal key function with Hermite(4) adjustments\n\n\nAIC= 10191.08\n\n\n\nHalf-normal key function selected.\n\ngrsp.uncos &lt;- ds(data=grsp, transect = \"point\",\n         key=\"unif\", truncation = \"10%\",  convert_units = cu)\n\nStarting AIC adjustment term selection.\n\n\nFitting uniform key function\n\n\nAIC= 10361.471\n\n\nFitting uniform key function with cosine(1) adjustments\n\n\nAIC= 10196.275\n\n\nFitting uniform key function with cosine(1,2) adjustments\n\n\nAIC= 10185.799\n\n\nFitting uniform key function with cosine(1,2,3) adjustments\n\n\nAIC= 10186.734\n\n\n\nUniform key function with cosine(1,2) adjustments selected.\n\ngrsp.hr &lt;- ds(data=grsp, transect = \"point\",\n         key=\"hr\", truncation = \"10%\",  convert_units = cu, adjustment = \"poly\")\n\nStarting AIC adjustment term selection.\n\n\nFitting hazard-rate key function\n\n\nAIC= 10188.776\n\n\nFitting hazard-rate key function with simple polynomial(4) adjustments\n\n\nAIC= 10190.153\n\n\n\nHazard-rate key function selected.\n\nsummarize_ds_models(grsp.hn, grsp.uncos, grsp.hr)\n\n                 Model                                      Key function\n2 \\\\texttt{grsp.uncos} Uniform with cosine adjustment terms of order 1,2\n3    \\\\texttt{grsp.hr}                                       Hazard-rate\n1    \\\\texttt{grsp.hn}                                       Half-normal\n  Formula C-vM p-value $\\\\hat{P_a}$ se($\\\\hat{P_a}$) $\\\\Delta$AIC\n2    &lt;NA&gt;    0.2498221    0.5978788       0.05379185     0.000000\n3      ~1    0.2614903    0.6271652       0.03066799     2.976262\n1      ~1    0.2182570    0.5401211       0.02297043     3.196061\n\nplot(grsp.uncos, pdf=TRUE, nc=25, main=\"GRSP, unicos, pooled detfn\")"
  },
  {
    "objectID": "rachel/rusten.html#constant-detectability-across-strata",
    "href": "rachel/rusten.html#constant-detectability-across-strata",
    "title": "Sandhills Grassland Birds",
    "section": "5 Constant detectability across strata?",
    "text": "5 Constant detectability across strata?\nClearly there are insufficient detections within strata to fit stratum-specific detection functions. However, as shown in Rexstad et al. (2023), bias will result from using a pooled detection function to estimate density at the stratum level if detectability differs between strata.\nThe defensible way to estimate stratum-specific detection probabilities with small stratum-specific detections is to use stratum as a covariate. This may not work for the large number of strata we have here. The hazard rate model was preferred for two of the three species and it was second-preferred for the GRSP, so attempt covariate modelling using hazard rate as key function.\n\nweme.hrstrat &lt;- ds(data=weme, transect=\"point\", key=\"hr\", truncation=\"10%\",\n                   convert_units = cu, formula=~Region.Label)\ndick.hrstrat &lt;- ds(data=dick, transect=\"point\", key=\"hr\", truncation=\"10%\",\n                   convert_units = cu, formula=~Region.Label)\ngrsp.hrstrat &lt;- ds(data=grsp, transect=\"point\", key=\"hr\", truncation=\"10%\",\n                   convert_units = cu, formula=~Region.Label)\n\n\n\n\n\n\n\nConvergence warning)\n\n\n\n\n\nThere are convergence problems with the meadowlark data when using stratum as a covariate\n\n\n\nContrast models with and without Region.Label covariate for each species to provide an evidence-based assessment of constant detectability across strata.\n\nAIC(weme.hr, weme.hrstrat)\nAIC(dick.hr, dick.hrstrat)\nAIC(grsp.uncos, grsp.hrstrat)\n\nIf you are fussy, you could use BIC rather than AIC.\nAs an experiment, use Group as strata and fit group as a covariate. Won’t work because Area specified for the grid, not group.\n\nexperiment &lt;- fourspec\nexperiment$Region.Label &lt;- experiment$Group\nweme.group &lt;- subset(experiment, Species==\"WEME\")\nweme.hrgroup &lt;- ds(data=weme.group, transect=\"point\", key=\"hr\", truncation=\"10%\",\n                   convert_units = cu, formula=~Region.Label)\n\nDifferent idea, remove Region.Label for which there are fewer than 13 detections\n\nweme.small &lt;- subset(weme, subset = !(Region.Label %in% \n                       c(\"GAR-LOWja\", \"GAR046-B\", \"WHE035-A\", \"GAR041-B\")))\nweme.hrsmall &lt;- ds(data=weme.small, transect=\"point\", key=\"hr\", truncation=\"10%\",\n                   convert_units = cu, formula=~Region.Label)\n\nModel contains covariate term(s): no adjustment terms will be included.\n\n\nFitting hazard-rate key function\n\n\n** Warning: Estimation routine failed to converge due to an unknown error in iteration  10. Using results from previous iteration. **\n\n\n** Warning: Estimation routine failed to converge due to an unknown error in iteration  10. Using results from previous iteration. **\n\n\nAIC= 9104.442\n\nsummary(weme.hrsmall)\n\n\nSummary for distance analysis \nNumber of observations :  931 \nDistance range         :  0  -  190 \n\nModel       : Hazard-rate key function \nAIC         :  9104.442 \nOptimisation:  mrds (nlminb) \n\nDetection function parameters\nScale coefficient(s):  \n                           estimate          se\n(Intercept)              4.94689036    22.82604\nRegion.LabelDismal E    -0.09895483    22.30074\nRegion.LabelDouble E    -0.47962636    21.68350\nRegion.LabelDouble M    -0.76187316    21.98531\nRegion.LabelDouble W     0.16640910    22.28694\nRegion.LabelGAR-ML-A     0.06320256    22.71438\nRegion.LabelGAR-PLU     -0.35632274    22.30461\nRegion.LabelGAR-WIL-A    0.54238218    22.55513\nRegion.LabelGAR-WIL-B   -0.04987811    22.55913\nRegion.LabelGAR-WIL-C   -0.45761589    22.21245\nRegion.LabelGAR045-A     0.01263804    22.38110\nRegion.LabelGAR045-B    -0.66855598    21.73829\nRegion.LabelGAR046-A    -0.17206158    22.27582\nRegion.LabelGAR046-C    -0.25647459    22.20771\nRegion.LabelGAR046-H    -0.18178593    22.38452\nRegion.LabelGAR046-M     0.75100304 93572.30400\nRegion.LabelGAR053-A    -0.36301999    21.89959\nRegion.LabelGAR053-B    -0.03884274    22.58571\nRegion.LabelGAR054      -0.28684332    22.14324\nRegion.LabelLOU-SMI-A    0.13368741    21.27201\nRegion.LabelLOU-SMI-B   -0.31320658    22.13866\nRegion.LabelLOU-SMI-C    0.67417979   429.65387\nRegion.LabelLOU-SWMB     0.66993726   678.65930\nRegion.LabelValentine A  0.02058352    22.56684\nRegion.LabelValentine B -0.45270254    22.58849\nRegion.LabelWeggener     0.83797603 34097.56869\nRegion.LabelWHE014       0.73150362 10816.59735\nRegion.LabelWHE035-B    -0.37006719    22.27794\nRegion.LabelWHE035-C     0.09896246    22.34715\n\nShape coefficient(s):  \n            estimate      se\n(Intercept) 1.979698 3.25163\n\n                        Estimate           SE       CV\nAverage p              0.3976593    0.6218265 1.563717\nN in covered region 2341.1999219 3661.5659399 1.563970\n\nSummary statistics:\n        Region   Area CoveredArea Effort   n   k       ER     se.ER      cv.ER\n1     BLA049-C  256.0   136.09379     12  41  12 3.416667 0.3361622 0.09838895\n2     Dismal E  256.0   136.09379     12  41  12 3.416667 0.5143153 0.15053130\n3     Double E  256.0   136.09379     12  55  12 4.583333 0.4344682 0.09479306\n4     Double M  256.0   136.09379     12  42  12 3.500000 0.2302831 0.06579517\n5     Double W  256.0   113.41149     10  21  10 2.100000 0.3480102 0.16571915\n6     GAR-ML-A  256.0   136.09379     12  29  12 2.416667 0.2289083 0.09472066\n7      GAR-PLU  170.7   102.07035      9  23   9 2.555556 0.3379313 0.13223397\n8    GAR-WIL-A  256.0   124.75264     11  12  11 1.090909 0.2845905 0.26087460\n9    GAR-WIL-B  256.0   136.09379     12  28  12 2.333333 0.2842676 0.12182898\n10   GAR-WIL-C  256.0   124.75264     11  38  11 3.454545 0.2073046 0.06000923\n11    GAR045-A  256.0   124.75264     11  30  11 2.727273 0.3835459 0.14063349\n12    GAR045-B  256.0   136.09379     12  51  12 4.250000 0.2500000 0.05882353\n13    GAR046-A  256.0   124.75264     11  18  11 1.636364 0.3377123 0.20637973\n14    GAR046-C  256.0   136.09379     12  47  12 3.916667 0.3128155 0.07986779\n15    GAR046-H  256.0   124.75264     11  34  11 3.090909 0.5633430 0.18225804\n16    GAR046-M  256.0   136.09379     12  22  12 1.833333 0.3658393 0.19954870\n17    GAR053-A  256.0   113.41149     10  36  10 3.600000 0.3399346 0.09442629\n18    GAR053-B  234.7   124.75264     11  28  11 2.545455 0.3659020 0.14374723\n19      GAR054  256.0   124.75264     11  38  11 3.454545 0.2816715 0.08153649\n20   LOU-SMI-A  256.0   136.09379     12  19  12 1.583333 0.3361622 0.21231299\n21   LOU-SMI-B  256.0   136.09379     12  51  12 4.250000 0.3046359 0.07167903\n22   LOU-SMI-C  256.0   136.09379     12  25  12 2.083333 0.2599048 0.12475430\n23    LOU-SWMB  256.0   136.09379     12  24  12 2.000000 0.2132007 0.10660036\n24 Valentine A  234.7   102.07035      9  14   9 1.555556 0.2939724 0.18898224\n25 Valentine B  256.0    79.38805      7  20   7 2.857143 0.3400680 0.11902381\n26    Weggener  256.0   136.09379     12  42  12 3.500000 0.3793935 0.10839813\n27      WHE014  256.0   136.09379     12  25  12 2.083333 0.4515685 0.21675290\n28    WHE035-B  256.0   136.09379     12  49  12 4.083333 0.4680445 0.11462314\n29    WHE035-C  256.0   113.41149     10  28  10 2.800000 0.4422166 0.15793451\n30       Total 7296.1  3674.53243    324 931 324 2.860505 0.0656242 0.02294147\n\nAbundance:\n         Label   Estimate          se         cv         lcl         ucl\n1     BLA049-C  118.65969 4477.764288 37.7361876   0.5989641 23507.45543\n2     Dismal E  140.97149   62.333619  0.4421718  61.4490221   323.40566\n3     Double E  391.94908  524.712896  1.3387272  53.6457497  2863.67669\n4     Double M  524.28227  359.875153  0.6864149 154.8752890  1774.79504\n5     Double W   57.00472   40.337003  0.7076081  16.3196603   199.11803\n6     GAR-ML-A   75.81512   11.823814  0.1559559  55.6832852   103.22546\n7      GAR-PLU  114.40364   28.967097  0.2532008  69.7726587   187.58342\n8    GAR-WIL-A   24.62778    6.430755  0.2611180  13.9004825    43.63355\n9    GAR-WIL-B   88.24337   15.488576  0.1755211  62.1541528   125.28353\n10   GAR-WIL-C  282.87319   90.987640  0.3216552 152.8041130   523.65896\n11    GAR045-A   92.75332   41.275873  0.4450070  40.2421991   213.78500\n12    GAR045-B  528.62689  626.855487  1.1858184  84.0379798  3325.23922\n13    GAR046-A   77.21377   34.919538  0.4522449  32.9804296   180.77286\n14    GAR046-C  216.80261   95.668588  0.4412705  94.7408202   496.12586\n15    GAR046-H  148.52279   39.713093  0.2673872  87.5028900   252.09476\n16    GAR046-M   41.38322    8.257969  0.1995487  26.7879523    63.93065\n17    GAR053-A  244.86947  236.555434  0.9660471  49.7638010  1204.91312\n18    GAR053-B   86.58029   16.815754  0.1942215  58.5342516   128.06427\n19      GAR054  202.70466  109.888116  0.5421095  74.8549331   548.91745\n20   LOU-SMI-A   44.84209   92.311389  2.0585881   3.5883035   560.37985\n21   LOU-SMI-B  262.40580  138.790289  0.5289147  99.0049648   695.48839\n22   LOU-SMI-C   47.02639    5.866759  0.1247546  35.7727249    61.82033\n23    LOU-SWMB   45.14534    4.812602  0.1066024  35.7275236    57.04569\n24 Valentine A   47.87434   13.874005  0.2898005  27.0067330    84.86595\n25 Valentine B  231.70210  111.364557  0.4806368  94.6498471   567.20499\n26    Weggener   79.00434    8.563922  0.1083981  62.2785148   100.22213\n27      WHE014   47.02639   10.193107  0.2167529  29.3444730    75.36279\n28    WHE035-B  281.59175   72.790376  0.2584961 170.6167697   464.74864\n29    WHE035-C   83.25751   49.674232  0.5966336  28.1738385   246.03725\n30       Total 4628.16343 6918.676171  1.4949075 551.9504039 38807.64753\n          df\n1  901.01225\n2  478.78483\n3  908.21435\n4  911.36846\n5  754.30579\n6   78.04971\n7  101.15619\n8   10.03737\n9   46.73217\n10 865.72011\n11 527.23176\n12 904.99960\n13 198.70507\n14 880.34979\n15  45.65222\n16  11.00000\n17 909.98951\n18  33.07643\n19 899.76124\n20 911.84471\n21 908.96802\n22  11.00010\n23  11.00085\n24  43.53263\n25 623.16640\n26  11.00000\n27  11.00000\n28 236.35264\n29 664.30306\n30 901.38242\n\nDensity:\n         Label   Estimate          se         cv         lcl        ucl\n1     BLA049-C 0.46351441 17.49126675 37.7361876 0.002339704 91.8259978\n2     Dismal E 0.55066989  0.24349070  0.4421718 0.240035243  1.2633034\n3     Double E 1.53105110  2.04965975  1.3387272 0.209553710 11.1862371\n4     Double M 2.04797760  1.40576231  0.6864149 0.604981598  6.9327931\n5     Double W 0.22267470  0.15756642  0.7076081 0.063748673  0.7778048\n6     GAR-ML-A 0.29615282  0.04618677  0.1559559 0.217512833  0.4032245\n7      GAR-PLU 0.67020295  0.16969594  0.2532008 0.408744339  1.0989070\n8    GAR-WIL-A 0.09620226  0.02512014  0.2611180 0.054298760  0.1704436\n9    GAR-WIL-B 0.34470065  0.06050225  0.1755211 0.242789659  0.4893888\n10   GAR-WIL-C 1.10497341  0.35542047  0.3216552 0.596891066  2.0455428\n11    GAR045-A 0.36231766  0.16123388  0.4450070 0.157196090  0.8350976\n12    GAR045-B 2.06494878  2.44865425  1.1858184 0.328273359 12.9892157\n13    GAR046-A 0.30161630  0.13640445  0.4522449 0.128829803  0.7061440\n14    GAR046-C 0.84688519  0.37370542  0.4412705 0.370081329  1.9379916\n15    GAR046-H 0.58016717  0.15512927  0.2673872 0.341808164  0.9847452\n16    GAR046-M 0.16165322  0.03225769  0.1995487 0.104640439  0.2497291\n17    GAR053-A 0.95652136  0.92404466  0.9660471 0.194389848  4.7066919\n18    GAR053-B 0.36889769  0.07164787  0.1942215 0.249400305  0.5456509\n19      GAR054 0.79181508  0.42925045  0.5421095 0.292402083  2.1442088\n20   LOU-SMI-A 0.17516441  0.36059137  2.0585881 0.014016810  2.1889838\n21   LOU-SMI-B 1.02502265  0.54214957  0.5289147 0.386738144  2.7167515\n22   LOU-SMI-C 0.18369684  0.02291703  0.1247546 0.139737207  0.2414856\n23    LOU-SWMB 0.17634897  0.01879923  0.1066024 0.139560639  0.2228347\n24 Valentine A 0.20398098  0.05911378  0.2898005 0.115069165  0.3615933\n25 Valentine B 0.90508635  0.43501780  0.4806368 0.369725965  2.2156445\n26    Weggener 0.30861069  0.03345282  0.1083981 0.243275448  0.3914927\n27      WHE014 0.18369684  0.03981682  0.2167529 0.114626848  0.2943859\n28    WHE035-B 1.09996776  0.28433741  0.2584961 0.666471757  1.8154244\n29    WHE035-C 0.32522467  0.19403997  0.5966336 0.110054057  0.9610830\n30       Total 0.63433388  0.94827047  1.4949075 0.075650060  5.3189577\n          df\n1  901.01225\n2  478.78483\n3  908.21435\n4  911.36846\n5  754.30579\n6   78.04971\n7  101.15619\n8   10.03737\n9   46.73217\n10 865.72011\n11 527.23176\n12 904.99960\n13 198.70507\n14 880.34979\n15  45.65222\n16  11.00000\n17 909.98951\n18  33.07643\n19 899.76124\n20 911.84471\n21 908.96802\n22  11.00010\n23  11.00085\n24  43.53263\n25 623.16640\n26  11.00000\n27  11.00000\n28 236.35264\n29 664.30306\n30 901.38242\n\n\nThe convergence may still not be perfect; however the CVs at the stratum level are reasonable, staying below 0.35.\n\nplot(weme.hrsmall, pdf=TRUE)\nrlabels &lt;- unique(weme.small$Region.Label)\nfor (i in 1:length(rlabels)) {\n  add_df_covar_line(weme.hrsmall, data=data.frame(Region.Label=rlabels[i]),\n                    lwd=2, lty=1, pdf=TRUE, col=colours(TRUE)[i])\n}\nlegend(\"topright\", title=\"Strata\", legend=rlabels,\n       lwd=2, lty=1, col=colours(TRUE), cex=0.8)\n\n\n\n\n\n\n\n\nThe plot of the probability density functions at the stratum level indicates one stratum with a very different detection function shape compared to the rest of the strata (WHE014). This may explain the convergence challenge. That stratum might be a candidate for exclusion.\n\nhist(weme$distance[weme$Region.Label==\"WHE014\"], xlim=c(0,190), nc=10,\n     xlab=\"Radial distance\", main=\"Stratum WHE014 detections of WEME\")\n\n\n\n\n\n\n\n\nNote the SE of the stratum-\\(\\hat{\\beta}\\) associated with stratum WHE014 1.0816597^{4}"
  },
  {
    "objectID": "cassidy/lathrom.html#becoming-acquainted-with-data",
    "href": "cassidy/lathrom.html#becoming-acquainted-with-data",
    "title": "Ft Riley bumblebees",
    "section": "Becoming acquainted with data",
    "text": "Becoming acquainted with data\nReorganise the data columns just a bit\n\nlibrary(readxl)\nyr22 &lt;- read_xlsx(path=\"data/2022-2024_bee_ds_data.xlsx\",\n                     sheet = \"2022\")\n\nNew names:\n• `Sample.Label` -&gt; `Sample.Label...5`\n• `Sample.Label` -&gt; `Sample.Label...12`\n\nyr23 &lt;- read_xlsx(path=\"data/2022-2024_bee_ds_data.xlsx\",\n                     sheet = \"2023\")\nyr24 &lt;- read_xlsx(path=\"data/2022-2024_bee_ds_data.xlsx\",\n                     sheet = \"2024\")\nyr22$Sample.Label...12 &lt;- NULL\nyr22$Sample.Label &lt;- yr22$Sample.Label...5\nyr22$Sample.Label...5 &lt;- NULL\nyr22 &lt;- yr22[yr22$distance&gt;=0,]  # a couple of -1 values\n(numstrat &lt;- unique(yr22$Region.Label))\n\n[1] NA     \"FRMR\"\n\n(numtrans &lt;- unique(yr22$Sample.Label))\n\n  [1]  NA   2   3   4   5   6   7   8   9  11  14  15  17  20  21  22  23  25\n [19]  26  28  29  30  32  33  34  35  36  37  38  39  40  41  42  43  44  45\n [37]  46  47  48  49  51  52  53  54  55  56  57  58  59  61  62  63  64  65\n [55]  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  83  84  85\n [73]  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103\n [91] 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121\n[109] 122 123 124 126 127 128 130 131 132 134 135 136 137 138 139 140 141 142\n[127] 143 144 145 146 147 148 149 150 151\n\n(numspec &lt;- unique(yr22$species))\n\n[1] NA          \"bombus\"    \"carpenter\" \"unknown\"   \"bumble\"   \n\n\n\nt22 &lt;- table(yr22$species, yr22$sample.bout)\nt23 &lt;- table(yr23$species, yr23$sample.bout)\nt24 &lt;- table(yr24$species, yr24$sample.bout)\n\nhistfn &lt;- function(frame, spec, bout) {\n  hist(frame$distance[frame$species==spec & frame$sample.bout==bout],\n       main=paste(spec, \" bout=\", bout), xlab=\"Distance\")\n}\nhistfn(yr22, \"bombus\", 1)\nhistfn(yr22, \"bombus\", 2)\nhistfn(yr22, \"carpenter\", 1)\nhistfn(yr22, \"carpenter\", 2)\nhistfn(yr22, \"unknown\", 1)\nhistfn(yr22, \"unknown\", 2)"
  },
  {
    "objectID": "cassidy/lathrom.html#construct-region-table-and-sample-tables",
    "href": "cassidy/lathrom.html#construct-region-table-and-sample-tables",
    "title": "Ft Riley bumblebees",
    "section": "4.1 Construct region table and sample tables",
    "text": "4.1 Construct region table and sample tables\n\n\n\n\n\n\nThe following step is critical\n\n\n\n\n\n\nIf the following specification of the survey design is not followed, the analysis will issue no complaints and will produce density estimates that appear to be quite wonderful.\nHowever, they will be wrong.\nBecause the stratum redefinition destroys the information about the survey design.\nInstead, the software assumes there were only transects on which detections of the species x bout combinations were made.\nAlways check the summary output from your fitted models to make sure the correct number of transects are represented.\n\n\n\n\n\nyr24$Region.Label &lt;- paste0(yr24$species, yr24$sample.bout)\nnew_region_table &lt;- data.frame(Region.Label=unique(yr24$Region.Label),\n                               Area=28383)\nnew_sample_table &lt;- data.frame(Sample.Label=rep(seq(1,151), 19),\n                               Region.Label=rep(unique(yr24$Region.Label), 151),\n                               Effort=rep(500, 19*151))\n\n\nyr24$Region.Label &lt;- paste0(yr24$species, yr24$sample.bout)\nyr24_hn_2level &lt;- ds(yr24, key=\"hn\", truncation = \"10%\", convert_units = cu,\n                     region_table = new_region_table,\n                     sample_table = new_sample_table,\n                     formula=~species+as.factor(sample.bout))\nyr24_hr_2level &lt;- ds(yr24, key=\"hr\", truncation = \"10%\", convert_units = cu,\n                     region_table = new_region_table,\n                     sample_table = new_sample_table,\n                     formula=~species+as.factor(sample.bout))\nyr24_hn_species &lt;- ds(yr24, key=\"hn\", truncation = \"10%\", convert_units = cu,\n                     region_table = new_region_table,\n                     sample_table = new_sample_table,\n                     formula=~species)\nyr24_hr_species &lt;- ds(yr24, key=\"hr\", truncation = \"10%\", convert_units = cu,\n                     region_table = new_region_table,\n                     sample_table = new_sample_table,\n                     formula=~species)\nyr24_hn_bout &lt;- ds(yr24, key=\"hn\", truncation = \"10%\", convert_units = cu,\n                     region_table = new_region_table,\n                     sample_table = new_sample_table,\n                     formula=~as.factor(sample.bout))\nyr24_hr_bout &lt;- ds(yr24, key=\"hr\", truncation = \"10%\", convert_units = cu,\n                     region_table = new_region_table,\n                     sample_table = new_sample_table,\n                     formula=~as.factor(sample.bout))\nyr24_hn &lt;- ds(yr24, key=\"hn\", truncation = \"10%\", convert_units = cu,\n                     region_table = new_region_table,\n                     sample_table = new_sample_table)\nyr24_hr &lt;- ds(yr24, key=\"hr\", truncation = \"10%\", convert_units = cu,\n                     region_table = new_region_table,\n                     sample_table = new_sample_table)\nknitr::kable(summarize_ds_models(#yr24_hn, yr24_hr, \n                    yr24_hn_bout, yr24_hr_bout, \n                    yr24_hn_species, yr24_hr_species, \n                    yr24_hn_2level, yr24_hr_2level)[, c(2:7)],\n             digits=3, row.names=FALSE,\n             caption=\"Model criticism candidate model set 2024\")\n\n\nModel criticism candidate model set 2024\n\n\n\n\n\n\n\n\n\n\nKey function\nFormula\nC-vM p-value\n\\(\\hat{P_a}\\)\nse(\\(\\hat{P_a}\\))\n\\(\\Delta\\)AIC\n\n\n\n\nHazard-rate\n~species + as.factor(sample.bout)\n0.854\n0.338\n0.014\n0.000\n\n\nHazard-rate\n~species\n0.831\n0.335\n0.014\n2.851\n\n\nHazard-rate\n~as.factor(sample.bout)\n0.955\n0.344\n0.014\n6.120\n\n\nHalf-normal\n~species + as.factor(sample.bout)\n0.000\n0.427\n0.008\n84.245\n\n\nHalf-normal\n~as.factor(sample.bout)\n0.000\n0.431\n0.008\n86.072\n\n\nHalf-normal\n~species\n0.000\n0.429\n0.008\n90.691\n\n\n\n\nknitr::kable(summary(yr24_hr_2level$ddf)$coeff$key.scale, \n             caption=\"Looking for convergence problems in covariate coefficients\")\n\n\nLooking for convergence problems in covariate coefficients\n\n\n\nestimate\nse\n\n\n\n\n(Intercept)\n2.3163705\n0.1768905\n\n\nspeciesamerican\n-0.1288956\n0.1958475\n\n\nspeciesblack_gold\n0.3598236\n0.2640821\n\n\nspeciesbombus\n0.2680591\n0.3690617\n\n\nspeciesbrown_belted\n0.0099796\n0.1846799\n\n\nspeciescarpenter\n-0.4039568\n0.1873527\n\n\nspecieseastern\n-0.0423246\n0.3281912\n\n\nspeciessouthern_plains\n0.0507996\n0.2260533\n\n\nspeciestwsp\n-0.1139367\n0.4077639\n\n\nspeciesunk\n-0.4962881\n0.2450548\n\n\nas.factor(sample.bout)2\n-0.2066934\n0.0939350"
  },
  {
    "objectID": "cassidy/lathrom.html#apply-this-function-to-the-yr24_hr_2level-fitted-model",
    "href": "cassidy/lathrom.html#apply-this-function-to-the-yr24_hr_2level-fitted-model",
    "title": "Ft Riley bumblebees",
    "section": "apply this function to the yr24_hr_2level fitted model",
    "text": "apply this function to the yr24_hr_2level fitted model\n\ncoefs &lt;- yr24_hr_2level$ddf$par\nxmax &lt;- 38.59703\nxvals &lt;- seq(0,xmax, length=100)\nam1 &lt;- gz(z=xvals, key=\"HR\",beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n          sigcoef = c(coefs[\"speciesamerican\"]))\nam2 &lt;- gz(z=xvals, key=\"HR\",beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n          sigcoef = c(coefs[\"speciesamerican\"], coefs[\"as.factor.sample.bout.2\"]))\nbomb1 &lt;- gz(z=xvals, key=\"HR\",beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n          sigcoef = c(coefs[\"speciesbombus\"]))\nbomb2 &lt;- gz(z=xvals, key=\"HR\",beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n          sigcoef = c(coefs[\"speciesbombus\"], coefs[\"as.factor.sample.bout.2\"]))\nplot(xvals, am1, type=\"l\")\nlines(xvals, am2, col=\"blue\")\nlines(xvals, bomb1, col=\"darkgreen\")\nlines(xvals, bomb2, col=\"red\")"
  },
  {
    "objectID": "cassidy/lathrom.html#now-for-the-integration-and-conversion-to-detection-probability",
    "href": "cassidy/lathrom.html#now-for-the-integration-and-conversion-to-detection-probability",
    "title": "Ft Riley bumblebees",
    "section": "now for the integration and conversion to detection probability",
    "text": "now for the integration and conversion to detection probability\n\nam1_p_int &lt;- integrate(gz, lower=0, upper=xmax, key=\"HR\",\n                    beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n                    sigcoef = c(coefs[\"speciesamerican\"]))$value / xmax\nam2_p_int &lt;- integrate(gz, lower=0, upper=xmax, key=\"HR\",\n                    beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n                    sigcoef = c(coefs[\"speciesamerican\"], coefs[\"as.factor.sample.bout.2\"]))$value / xmax\nbomb1_p_int &lt;- integrate(gz, lower=0, upper=xmax, key=\"HR\",\n                    beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n                    sigcoef = c(coefs[\"speciesbombus\"]))$value / xmax\nbomb2_p_int &lt;- integrate(gz, lower=0, upper=xmax, key=\"HR\",\n                    beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n                    sigcoef = c(coefs[\"speciesbombus\"], coefs[\"as.factor.sample.bout.2\"]))$value / xmax"
  },
  {
    "objectID": "cassidy/lathrom.html#do-the-integrated-pa-correspond-to-reported-densities",
    "href": "cassidy/lathrom.html#do-the-integrated-pa-correspond-to-reported-densities",
    "title": "Ft Riley bumblebees",
    "section": "4.5 Do the integrated Pa correspond to reported densities?",
    "text": "4.5 Do the integrated Pa correspond to reported densities?\nRecall our formula to estimate density:\n\\[\\hat{D} = \\frac{\\hat{P}_a \\cdot n}{a}\\] where \\(n\\) is number of detections and \\(a\\) is covered area. Both of these quantities appear in the fitted model object, along with \\(\\hat{D}\\) for each species x bout combination.\nWe can rearrange the above formula to solve for \\(\\hat{P}_a\\):\n\\[\\hat{P}_a = \\frac{n}{\\hat{D} \\cdot a}\\] The following code chunk carries out this method of deriving \\(\\hat{P}_a\\) and compares them with the original method of computing the integral of the detection function and dividing by truncation distance, \\(w\\).\n\nsumm &lt;- yr24_hr_2level$dht$individuals$summary\ncoveredarea &lt;- yr24_hr_2level$dht$individuals$summary$CoveredArea[1]\nd_est &lt;- yr24_hr_2level$dht$individuals$D\n\nam1_p_data &lt;- summ[summ$Region==\"american1\", \"n\"] / (d_est[d_est$Label==\"american1\", \"Estimate\"] * coveredarea)\nam2_p_data &lt;- summ[summ$Region==\"american2\", \"n\"] / (d_est[d_est$Label==\"american2\", \"Estimate\"] * coveredarea)\nbomb1_p_data &lt;- summ[summ$Region==\"bombus1\", \"n\"] / (d_est[d_est$Label==\"bombus1\", \"Estimate\"] * coveredarea)\nbomb2_p_data &lt;- summ[summ$Region==\"bombus2\", \"n\"] / (d_est[d_est$Label==\"bombus2\", \"Estimate\"] * coveredarea)\n\nall.equal(am1_p_int, am1_p_data)\n\n[1] \"Mean relative difference: 1.076724e-06\"\n\nall.equal(am2_p_int, am2_p_data)\n\n[1] \"Mean relative difference: 3.448128e-08\"\n\nall.equal(bomb1_p_int, bomb1_p_data)\n\n[1] \"Mean relative difference: 2.311959e-06\"\n\nall.equal(bomb2_p_int, bomb2_p_data)\n\n[1] \"Mean relative difference: 4.616678e-07\"\n\n\nYes, the integration results in a \\(\\hat{P}_a\\) equivalent to that used in the estimates produced by the software (as if there was any doubt).\nNow that the detection probability estimate dilemma is sorted, let’s look at the objects of ecological interest, namely the species- and bout-specific density estimates."
  },
  {
    "objectID": "cassidy/lathrom.html#objective",
    "href": "cassidy/lathrom.html#objective",
    "title": "Ft Riley bumblebees",
    "section": "",
    "text": "evaluate environmental factors affecting bumblebee density and abundance using distance sampling methods\n\n\n\n\n\n\n\nMultiple years of data, my approach\n\n\n\n\n\nThere are three years of survey data. The first year (2022) was described as a pilot survey, so I will not thoroughly examine the 2022 data."
  },
  {
    "objectID": "cassidy/lathrom.html#exploratory-data-analysis-for-2024",
    "href": "cassidy/lathrom.html#exploratory-data-analysis-for-2024",
    "title": "Ft Riley bumblebees",
    "section": "Exploratory data analysis for 2024",
    "text": "Exploratory data analysis for 2024\n\nlibrary(readxl)\nyr24 &lt;- read_xlsx(path=\"data/2022-2024_bee_ds_data.xlsx\", sheet = \"2024\")\n(numstrat &lt;- unique(yr24$Region.Label))\n\n[1] \"FRMR\"\n\n(numtrans &lt;- unique(yr24$Sample.Label))\n\n  [1]  61  63   6   5   4  84  74  65  31  12  11  88  87  86  91 105 109 106\n [19]  97  96  95  94 117 122 127 126 131  54 151 150 149 148  80  24  32  67\n [37]  64   8  57  56  55  90 110 112 115   3 113 114  89 140  82  81  79  77\n [55]  20  35   7   2  59  47  45  44  42  40  39  41  58 146 147 145 144  33\n [73] 123 124 125 128 130 116 118 119 120 121  52  53  68  69  70  62 103  66\n [91] 108  28  27  85  83  78  75  76   1  37  36 135 137 138 107  99 104  73\n[109]  72 132  71 134 143  60  25  23  26  30 136 139  22 102 100 101  51  50\n[127]  49  48 129   9  98  92  93  43  15\n\n(numspec &lt;- unique(yr24$species))\n\n [1] \"brown_belted\"    \"unk\"             \"carpenter\"       \"american\"       \n [5] \"twsp\"            \"AMER_BG\"         \"black_gold\"      \"southern_plains\"\n [9] \"eastern\"         \"bombus\"         \n\nt24 &lt;- table(yr24$species, yr24$sample.bout)\nknitr::kable(t24, caption=\"Approximate detections by species and bout for 2024\")\n\n\nApproximate detections by species and bout for 2024\n\n\n\n1\n2\n\n\n\n\nAMER_BG\n52\n33\n\n\namerican\n90\n108\n\n\nblack_gold\n23\n34\n\n\nbombus\n22\n5\n\n\nbrown_belted\n178\n197\n\n\ncarpenter\n198\n86\n\n\neastern\n28\n4\n\n\nsouthern_plains\n65\n52\n\n\ntwsp\n15\n0\n\n\nunk\n49\n14\n\n\n\n\n\nTwo things to note about the table above: - many detections for some species and - few detections for species I presume are rare (we’ll deal with that shortly).\n\n\n\n\n\n\nMy presumption about objectives\n\n\n\n\n\n\nI’m guessing Cassidy would like estimates by species and by sampling bout\nWe could easily ignore sampling bout and pool the data across bouts; this will produce density estimates that are the average density across the bouts.\nRather than pooling, I’ll take the more difficult analytical approach of producing species- and bout-specific density estimates.\n\n\n\n\nBefore starting the modelling, let’s come to grips with the distribution of perpendicular detection distances for species and bout combinations. This will give insight about what is in store for us when modelling begins.\nhistfn &lt;- function(frame, spec) {\n  hist(frame$distance[frame$species==spec & frame$sample.bout==1],\n       main=paste(spec, \" bout=May/June\"), xlab=\"Distance\", nc=20)\n  hist(frame$distance[frame$species==spec & frame$sample.bout==2],\n       main=paste(spec, \" bout=July/August\"), xlab=\"Distance\", nc=20)\n}\nhistfn(yr24, \"AMER_BG\")\nhistfn(yr24, \"american\")\nhistfn(yr24, \"black_gold\")\nhistfn(yr24, \"brown_belted\")\nhistfn(yr24, \"carpenter\")\nhistfn(yr24, \"southern_plains\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClearly there will be a struggle to fit detection function models to some of the species x bout combinations. Before we attack that problem, let’s tackle a simpler problem: estimating density for the common “brown_belted”."
  },
  {
    "objectID": "cassidy/lathrom.html#brown-belted-analysis",
    "href": "cassidy/lathrom.html#brown-belted-analysis",
    "title": "Ft Riley bumblebees",
    "section": "Brown belted analysis",
    "text": "Brown belted analysis\nThis species has nearly 200 detections for each sampling bout. Hence, if we wanted bout-specific estimates of density for this species, the most straightforward approach would be to simply pluck detections of brown_belted from the 2024 data frame.\n\nbb_bees_b1 &lt;- subset(yr24, species==\"brown_belted\" & sample.bout==1)\nbb_bees_b2 &lt;- subset(yr24, species==\"brown_belted\" & sample.bout==2)\n\nA quick check of the integrity of the survey design in the subsetted data shows:\n\nprint(length(unique(bb_bees_b1$Sample.Label)))\n\n[1] 53\n\nprint(length(unique(bb_bees_b2$Sample.Label)))\n\n[1] 45\n\n\nEven this most common species is only seen on little more than one-third of the 151 transects surveyed. If we carried on like this, we would produce extremely positively biased estimates of density.\nSolution, specify survey design manually using two arguments to the ds function: region_table and sample_table.\n\nbb_reg_tab1 &lt;- data.frame(Region.Label=\"FRMR\", Area=yr24$Area[1])\nbb_reg_tab2 &lt;- data.frame(Region.Label=\"FRMR\", Area=yr24$Area[1])\nbb_sam_tab1 &lt;- data.frame(Sample.Label=seq(1, 151),\n                         Region.Label=rep(\"FRMR\",151),\n                         Effort=rep(500,151))\nbb_sam_tab2 &lt;- data.frame(Sample.Label=seq(1, 151),\n                         Region.Label=rep(\"FRMR\",151),\n                         Effort=rep(500,151))"
  },
  {
    "objectID": "cassidy/testchild.html",
    "href": "cassidy/testchild.html",
    "title": "I am test child",
    "section": "",
    "text": "I am test child\n\nhist(runif(1000))"
  },
  {
    "objectID": "cassidy/lathrom.html#apply-function-to-the-selected-yr24_hr_2level-model",
    "href": "cassidy/lathrom.html#apply-function-to-the-selected-yr24_hr_2level-model",
    "title": "Ft Riley bumblebees",
    "section": "4.3 Apply function to the selected yr24_hr_2level model",
    "text": "4.3 Apply function to the selected yr24_hr_2level model\nCode below plucks out the relevant estimated coefficients from our model that included species and bout as covariates. I demonstrate only for two species and the two bouts. Code then plots the derived detection function from the fitted covariate coefficients. This gives us a sense check whether we’ve picked up the coefficients correctly.\n\ncoefs &lt;- yr24_hr_2level$ddf$par\nxmax &lt;- unname(yr24_hr_2level$ddf$meta.data$width)\nxvals &lt;- seq(0,xmax, length=100)\nam1 &lt;- gz(z=xvals, key=\"HR\",beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n          sigcoef = c(coefs[\"speciesamerican\"]))\nam2 &lt;- gz(z=xvals, key=\"HR\",beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n          sigcoef = c(coefs[\"speciesamerican\"], coefs[\"as.factor.sample.bout.2\"]))\nbomb1 &lt;- gz(z=xvals, key=\"HR\",beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n          sigcoef = c(coefs[\"speciesbombus\"]))\nbomb2 &lt;- gz(z=xvals, key=\"HR\",beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n          sigcoef = c(coefs[\"speciesbombus\"], coefs[\"as.factor.sample.bout.2\"]))\nplot(xvals, am1, lwd=2, type=\"l\",\n     main=\"Construct species x bout detection functions manually\",\n     xlab=\"Distance\", ylab=\"Detection probability\")\nlines(xvals, am2, lwd=2, col=\"blue\")\nlines(xvals, bomb1, lwd=2, col=\"darkgreen\")\nlines(xvals, bomb2, lwd=2, col=\"red\")\nlegend(\"topright\", legend=c(\"American1\", \"American2\", \"Bombus1\", \"Bombus2\"),\n       col=c(\"black\",\"blue\",\"darkgreen\",\"red\"), lwd=2)"
  },
  {
    "objectID": "cassidy/lathrom.html#integration-and-conversion-to-detection-probability",
    "href": "cassidy/lathrom.html#integration-and-conversion-to-detection-probability",
    "title": "Ft Riley bumblebees",
    "section": "4.4 Integration and conversion to detection probability",
    "text": "4.4 Integration and conversion to detection probability\nSense check completed, we now use our gz function to “manually” compute species- and bout-specific detection probabilities for the for examples created above. The formula being applied here (see Lecture 2 of notes) is \\(\\hat{P}_a\\) is “area under curve” divided by “area of rectangle”\n\\[\\hat{P}_a=\\frac{\\int^w_0 \\hat{g}(x) dx}{w} \\]\n\nam1_p_int &lt;- integrate(gz, lower=0, upper=xmax, key=\"HR\",\n                    beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n                    sigcoef = c(coefs[\"speciesamerican\"]))$value / xmax\nam2_p_int &lt;- integrate(gz, lower=0, upper=xmax, key=\"HR\",\n                    beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n                    sigcoef = c(coefs[\"speciesamerican\"], coefs[\"as.factor.sample.bout.2\"]))$value / xmax\nbomb1_p_int &lt;- integrate(gz, lower=0, upper=xmax, key=\"HR\",\n                    beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n                    sigcoef = c(coefs[\"speciesbombus\"]))$value / xmax\nbomb2_p_int &lt;- integrate(gz, lower=0, upper=xmax, key=\"HR\",\n                    beta=coefs[\"V1\"], sigintercept = coefs[\"X.Intercept.\"], \n                    sigcoef = c(coefs[\"speciesbombus\"], coefs[\"as.factor.sample.bout.2\"]))$value / xmax"
  },
  {
    "objectID": "cassidy/lathrom.html#data-organisation-complete-fit-some-models",
    "href": "cassidy/lathrom.html#data-organisation-complete-fit-some-models",
    "title": "Ft Riley bumblebees",
    "section": "3.1 Data organisation complete, fit some models",
    "text": "3.1 Data organisation complete, fit some models\nA glance at the histograms produced earlier suggests an abrupt drop in detection probability around 5-8m, suggesting the flexibility of the hazard rate model will be useful, but we fit the full series of candidates to each bout. Note too the existence of a small number of detections at great distances, they will not be very useful in our detection function modelling. We are likely to be more aggressive in our truncation than we might otherwise be when dealing with non-insect species.\n\nlibrary(Distance)\ncu &lt;- convert_units(\"meter\", \"meter\", \"hectare\")\nbbunicos &lt;- ds(data=bb_bees_b1, key=\"unif\", adj=\"cos\", convert_units = cu,\n               region_table = bb_reg_tab1, sample_table = bb_sam_tab1,\n               truncation = \"10%\")\nbbhnherm &lt;- ds(data=bb_bees_b1, key=\"hn\", adj=\"herm\", convert_units = cu,\n               region_table = bb_reg_tab1, sample_table = bb_sam_tab1,\n               truncation = \"10%\")\nbbhrsim &lt;- ds(data=bb_bees_b1, key=\"hr\", adj=\"poly\", convert_units = cu,\n               region_table = bb_reg_tab1, sample_table = bb_sam_tab1,\n               truncation = \"10%\")\nknitr::kable(summarize_ds_models(bbunicos, bbhnherm, bbhrsim)[, c(2:7)],\n             digits=3, row.names=FALSE,\n             caption=\"Model criticism candidate model set\\n brown_belted bout 1\")\n\n\nModel criticism candidate model set brown_belted bout 1\n\n\n\n\n\n\n\n\n\n\nKey function\nFormula\nC-vM p-value\n\\(\\hat{P_a}\\)\nse(\\(\\hat{P_a}\\))\n\\(\\Delta\\)AIC\n\n\n\n\nUniform with cosine adjustment terms of order 1,2\nNA\n0.769\n0.446\n0.030\n0.000\n\n\nHazard-rate\n~1\n0.859\n0.444\n0.044\n0.312\n\n\nHalf-normal\n~1\n0.307\n0.477\n0.026\n0.831\n\n\n\n\n\nDouble-check that we have the right number of transects:\n\nknitr::kable(bbunicos$dht$individuals$summary)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegion\nArea\nCoveredArea\nEffort\nn\nk\nER\nse.ER\ncv.ER\n\n\n\n\nFRMR\n28383\n551.7512\n75500\n160\n151\n0.0021192\n0.0003848\n0.1815787\n\n\n\n\n\n\n\n\n\n\n\nWhat did we learn from this?\n\n\n\n\n\n\nall models fit the data\n\\(\\Delta\\)AIC among candidates is small\nNot by coincidence, \\(\\hat{P}_a\\) are very similar across models\n\n\n\n\nBefore examining the density estimate, continue for sampling bout 2\n\nlibrary(Distance)\ncu &lt;- convert_units(\"meter\", \"meter\", \"hectare\")\nbbunicos2 &lt;- ds(data=bb_bees_b2, key=\"unif\", adj=\"cos\", convert_units = cu,\n               region_table = bb_reg_tab2, sample_table = bb_sam_tab2,\n               truncation = \"10%\")\nbbhnherm2 &lt;- ds(data=bb_bees_b2, key=\"hn\", adj=\"herm\", convert_units = cu,\n               region_table = bb_reg_tab2, sample_table = bb_sam_tab2,\n               truncation = \"10%\")\nbbhrsim2 &lt;- ds(data=bb_bees_b2, key=\"hr\", adj=\"poly\", convert_units = cu,\n               region_table = bb_reg_tab2, sample_table = bb_sam_tab2,\n               truncation = \"10%\")\nknitr::kable(summarize_ds_models(bbunicos2, bbhnherm2, bbhrsim2)[, c(2:7)],\n             digits=3, row.names=FALSE,\n             caption=\"Model criticism candidate model set\\n brown_belted bout 2\")\n\n\nModel criticism candidate model set brown_belted bout 2\n\n\n\n\n\n\n\n\n\n\nKey function\nFormula\nC-vM p-value\n\\(\\hat{P_a}\\)\nse(\\(\\hat{P_a}\\))\n\\(\\Delta\\)AIC\n\n\n\n\nHazard-rate\n~1\n0.712\n0.236\n0.025\n0.000\n\n\nUniform with cosine adjustment terms of order 1,2,3,4,5\nNA\n0.643\n0.227\n0.016\n5.307\n\n\nHalf-normal\n~1\n0.000\n0.358\n0.014\n42.282\n\n\n\n\n\nThe difference in \\(\\Delta\\)AIC among candidates is greater for bout 2, and you will see a bit more disparity between \\(\\hat{P}_a\\), particularly the non-fitting half normal model.\nLet’s look at the fit of the selected models for each bout:\nplot(bbunicos, nc=20, main=\"brown_belted, bout 1, unifcos\")\nplot(bbhrsim2, nc=20, main=\"brown_belted, bout 2, hazard rate\")\n\n\n\n\n\n\n\n\n\n\nLooking at the plots, I think I would truncate yet more aggressively again; to ~30m.\n\nbbunicosx &lt;- ds(data=bb_bees_b1, key=\"unif\", adj=\"cos\", convert_units = cu,\n               region_table = bb_reg_tab1, sample_table = bb_sam_tab1,\n               truncation = 31)\nbbhnhermx &lt;- ds(data=bb_bees_b1, key=\"hn\", adj=\"herm\", convert_units = cu,\n               region_table = bb_reg_tab1, sample_table = bb_sam_tab1,\n               truncation = 31)\nbbhrsimx &lt;- ds(data=bb_bees_b1, key=\"hr\", adj=\"poly\", convert_units = cu,\n               region_table = bb_reg_tab1, sample_table = bb_sam_tab1,\n               truncation = 31)\nbbunicos2x &lt;- ds(data=bb_bees_b2, key=\"unif\", adj=\"cos\", convert_units = cu,\n               region_table = bb_reg_tab2, sample_table = bb_sam_tab2,\n               truncation = 31)\nbbhnherm2x &lt;- ds(data=bb_bees_b2, key=\"hn\", adj=\"herm\", convert_units = cu,\n               region_table = bb_reg_tab2, sample_table = bb_sam_tab2,\n               truncation = 31)\nbbhrsim2x &lt;- ds(data=bb_bees_b2, key=\"hr\", adj=\"poly\", convert_units = cu,\n               region_table = bb_reg_tab2, sample_table = bb_sam_tab2,\n               truncation = 31)\nknitr::kable(summarize_ds_models(bbunicosx, bbhnhermx, bbhrsimx)[, c(2:7)],\n             digits=3, row.names=FALSE,\n             caption=\"Model criticism candidate model set\\n brown_belted bout 1 trunc=31\")\n\n\nModel criticism candidate model set brown_belted bout 1 trunc=31\n\n\n\n\n\n\n\n\n\n\nKey function\nFormula\nC-vM p-value\n\\(\\hat{P_a}\\)\nse(\\(\\hat{P_a}\\))\n\\(\\Delta\\)AIC\n\n\n\n\nUniform with cosine adjustment terms of order 1,2\nNA\n0.929\n0.487\n0.039\n0.000\n\n\nHalf-normal\n~1\n0.470\n0.532\n0.032\n0.277\n\n\nHazard-rate\n~1\n0.900\n0.495\n0.054\n0.609\n\n\n\n\nknitr::kable(summarize_ds_models(bbunicos2x, bbhnherm2x, bbhrsim2x)[, c(2:7)],\n             digits=3, row.names=FALSE,\n             caption=\"Model criticism candidate model set\\n brown_belted bout 2 trunc=31\")\n\n\nModel criticism candidate model set brown_belted bout 2 trunc=31\n\n\n\n\n\n\n\n\n\n\nKey function\nFormula\nC-vM p-value\n\\(\\hat{P_a}\\)\nse(\\(\\hat{P_a}\\))\n\\(\\Delta\\)AIC\n\n\n\n\nHazard-rate\n~1\n0.691\n0.431\n0.044\n0.000\n\n\nUniform with cosine adjustment terms of order 1,2,3\nNA\n0.358\n0.375\n0.032\n2.995\n\n\nHalf-normal\n~1\n0.093\n0.473\n0.025\n7.611\n\n\n\n\n\nplot(bbunicosx, nc=20, main=\"brown_belted, bout 1, unifcos, trunc=31\")\nplot(bbhrsim2x, nc=20, main=\"brown_belted, bout 2, hazard rate, trunc=31\")"
  },
  {
    "objectID": "cassidy/lathrom.html#did-truncation-changes-influence-estimated-density",
    "href": "cassidy/lathrom.html#did-truncation-changes-influence-estimated-density",
    "title": "Ft Riley bumblebees",
    "section": "3.2 Did truncation changes influence estimated density?",
    "text": "3.2 Did truncation changes influence estimated density?\nWe have seen there is no change in the models selected when changing the truncation distance, how about the estimates?\n\nbb1_10 &lt;- bbunicos$dht$individuals$D\nbb2_10 &lt;- bbhrsim$dht$individuals$D\nbb1_31 &lt;- bbunicosx$dht$individuals$D\nbb2_31 &lt;- bbhrsimx$dht$individuals$D\nestimates &lt;- rbind(bb1_10, bb1_31, bb2_10, bb2_31)\nestimates$Label &lt;- c(\"Bout1 10%\", \"Bout1 31m\", \"Bout2 10%\", \"Bout2 31m\")\nknitr::kable(estimates, digits=3,\n             caption=\"Estimates for brown belted, both bouts, different truncation distances\")\n\n\nEstimates for brown belted, both bouts, different truncation distances\n\n\nLabel\nEstimate\nse\ncv\nlcl\nucl\ndf\n\n\n\n\nBout1 10%\n0.651\n0.126\n0.193\n0.446\n0.950\n190.066\n\n\nBout1 31m\n0.684\n0.138\n0.201\n0.462\n1.013\n203.897\n\n\nBout2 10%\n0.653\n0.135\n0.206\n0.436\n0.976\n231.548\n\n\nBout2 31m\n0.673\n0.144\n0.214\n0.443\n1.022\n243.124\n\n\n\n\n\nWe see roughly a 3-5% difference in the point estimates from the more aggressive truncation. Place that difference in the context of the coefficient of variation (~20%).\n\nWe could continue to carry out this species by species, bout by bout analysis for the common species. However, eventually problems will arise when get to species like AMER_BG, black_gold, bombus, etc. If estimates for those species x bout combinations are important, we will have to “borrow strength” from other species to produce robust estimates for those rare species.\nWe “borrow strength” via the use of species and sampling bout as covariates in the detection function. I ignore other potential covariates, e.g. observer, because the property of pooling robustness ensures that bias is not introduced by ignoring such covariates."
  },
  {
    "objectID": "cassidy/lathrom.html#sec-brownbelt",
    "href": "cassidy/lathrom.html#sec-brownbelt",
    "title": "Ft Riley bumblebees",
    "section": "Brown belted analysis",
    "text": "Brown belted analysis\nThis species has nearly 200 detections for each sampling bout. Hence, if we wanted bout-specific estimates of density for this species, the most straightforward approach would be to simply pluck detections of brown_belted from the 2024 data frame.\n\nbb_bees_b1 &lt;- subset(yr24, species==\"brown_belted\" & sample.bout==1)\nbb_bees_b2 &lt;- subset(yr24, species==\"brown_belted\" & sample.bout==2)\n\nA quick check of the integrity of the survey design in the subsetted data shows:\n\nprint(length(unique(bb_bees_b1$Sample.Label)))\n\n[1] 53\n\nprint(length(unique(bb_bees_b2$Sample.Label)))\n\n[1] 45\n\n\nEven this most common species is only seen on little more than one-third of the 151 transects surveyed. If we carried on like this, we would produce extremely positively biased estimates of density.\nSolution, specify survey design manually using two arguments to the ds function: region_table and sample_table.\n\nbb_reg_tab1 &lt;- data.frame(Region.Label=\"FRMR\", Area=yr24$Area[1])\nbb_reg_tab2 &lt;- data.frame(Region.Label=\"FRMR\", Area=yr24$Area[1])\nbb_sam_tab1 &lt;- data.frame(Sample.Label=seq(1, 151),\n                         Region.Label=rep(\"FRMR\",151),\n                         Effort=rep(500,151))\nbb_sam_tab2 &lt;- data.frame(Sample.Label=seq(1, 151),\n                         Region.Label=rep(\"FRMR\",151),\n                         Effort=rep(500,151))"
  },
  {
    "objectID": "cassidy/lathrom.html#compare-estimates-from-basic-analysis",
    "href": "cassidy/lathrom.html#compare-estimates-from-basic-analysis",
    "title": "Ft Riley bumblebees",
    "section": "5.1 Compare estimates from “basic” analysis",
    "text": "5.1 Compare estimates from “basic” analysis\nRemember we started the modelling of the 2024 data by looking at the “brown_belted” species in Section 3. In that analysis, each sampling bout for that species was modelled in isolation, as there were sufficient numbers of detections of that species in each bout.\nAfter choosing the most appropriate models from that pair of analyses, density estimates were\n\nknitr::kable(estimates[c(1,3),], digits=2, caption=\"Estimated brown belted densities from 'standalone' analysis\")\n\n\nEstimated brown belted densities from ‘standalone’ analysis\n\n\n\nLabel\nEstimate\nse\ncv\nlcl\nucl\ndf\n\n\n\n\n1\nBout1 10%\n0.65\n0.13\n0.19\n0.45\n0.95\n190.07\n\n\n3\nBout2 10%\n0.65\n0.13\n0.21\n0.44\n0.98\n231.55\n\n\n\n\n\nCompare these point and interval estimates to those generated from our 2-level stratification model:\n\nbb1cov &lt;- yr24_hr_2level$dht$individuals$D[yr24_hr_2level$dht$individuals$D$Label==\"brown_belted1\", ]\nbb2cov &lt;- yr24_hr_2level$dht$individuals$D[yr24_hr_2level$dht$individuals$D$Label==\"brown_belted2\", ]\nknitr::kable(rbind(bb1cov, bb2cov)[,1:6], digits=3,\n             caption=\"Density estimates brown belted from HR covariate model\")\n\n\nDensity estimates brown belted from HR covariate model\n\n\n\nLabel\nEstimate\nse\ncv\nlcl\nucl\n\n\n\n\n9\nbrown_belted1\n0.676\n0.134\n0.198\n0.459\n0.995\n\n\n10\nbrown_belted2\n0.805\n0.167\n0.208\n0.537\n1.207\n\n\n\n\n\nThere is some difference in the point estimate for sampling bout 2; however the confidence intervals for the estimates from the two modelling approaches are quite similar. With reasonable data, which these are, the estimates are often robust to decisions made during analysis."
  },
  {
    "objectID": "cassidy/lathrom.html#given-the-preferred-model-is-ok-look-at-the-plot",
    "href": "cassidy/lathrom.html#given-the-preferred-model-is-ok-look-at-the-plot",
    "title": "Ft Riley bumblebees",
    "section": "4.2 Given the preferred model is OK, look at the plot",
    "text": "4.2 Given the preferred model is OK, look at the plot\n\nplot(yr24_hr_2level, nc=39)\nsp &lt;- unique(yr24$species)\nbo &lt;- unique(yr24$sample.bout)\npalette(\"ggplot2\")\nfor (i in 1:length(sp)) {\n  for (j in 1:length(bo))\n  add_df_covar_line(yr24_hr_2level, \n                    data=data.frame(species=sp[i], sample.bout=bo[j]),\n                    lwd=2, lty=1, col=rainbow(19)[i])\n}\nlegend(\"topright\", title=\"Spec x bout\", legend=unique(yr24$Region.Label),\n       lwd=2, lty=1, col=rainbow(19), cex=0.8)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpecies and bout-specific detection probability estimates\n\n\n\n\n\nAlthough the figure is pretty, we cannot deduce the species x bout-specific detection probabilities. Assuming these estimates are of interest, how do we produce them, given the software won’t cooperate with our request. Answer integrate detection function over distance for specific covariate levels.\n\n\n\nBelow is a function that will calculate detection probability for a given set of estimated covariate coefficients at a given perpendicular distance. We will use the function, in conjunction with the coefficients for a species and bout combination of interest.\n\ngz&lt;-function(z,\n             beta, sigintercept, sigcoef, DistWin=FALSE,\n             key=\"HR\", w=max(z)){\n#this is a generic detection function that returns the probability of detecting an animal\n#    z               generic distance (perpendicular) - can be scalar or vector\n#    beta            shape coefficient\n#    sigintercept  intercept coefficient for sigma\n#    sigcoef         coefficient for specific factor level\n#    DistWin         coefficients from Distance for Windows or from R\n#    key             the detection function key, works for hazard rate and half normal\n#    w               truncation distance, by default the max of the distances\n#\n#RETURNS: a probability\n  \n  if(key != \"HN\" & key != \"HR\") {\n    stop(\"Argument 'key' must be either HN or HR\")\n  }\n  if (DistWin) {\n    sigma &lt;- sigintercept + exp(sigcoef)\n    exponent &lt;- beta\n  } else {\n    numterms &lt;- length(sigcoef)\n    predictor &lt;- 0\n    for (i in 1:numterms) {\n      predictor &lt;- predictor + sigcoef[i]\n    }\n    sigma &lt;- exp(sigintercept + predictor)\n    exponent &lt;- exp(beta)\n  }\n  if(key==\"HR\") {\n    scale.dist &lt;- z/sigma\n    inside &lt;- -(scale.dist)^(-exponent)\n    gx &lt;- 1 - exp(inside)\n  } else {\n    scale.dist &lt;- z  # debatably don't scale for half normal\n    inside &lt;- -(scale.dist^2/(2*sigma^2))\n    gx &lt;- exp(inside)\n  }\n  return(gx)\n}"
  },
  {
    "objectID": "cassidy/lathrom.html#magical-estimates-for-rare-species",
    "href": "cassidy/lathrom.html#magical-estimates-for-rare-species",
    "title": "Ft Riley bumblebees",
    "section": "6.1 Magical estimates for rare species?",
    "text": "6.1 Magical estimates for rare species?\nDensity estimates are produced for all species in the data frame Table 1; even for species with as few as four detections (eastern2). Is that some kind of magic? No, look closely at the measures of precision associated with the species with small numbers of detection:\n\nlibrary(kableExtra)\nknitr::kable(table.attr=\"quarto-disable-processing=true\",\n             format=\"html\",\n             yr24_hr_2level$dht$individuals$D[, 1:6],\n             row.names = FALSE, digits=3) %&gt;%\n  row_spec(c(5:8,13:14,17), background = \"salmon\") %&gt;%\n  row_spec(c(18:20), strikeout=TRUE) %&gt;%\n  column_spec(c(2:6), width=\"4em\")\n\n\n \n  \n    Label \n    Estimate \n    se \n    cv \n    lcl \n    ucl \n  \n \n\n  \n    AMER_BG1 \n    0.193 \n    0.046 \n    0.237 \n    0.122 \n    0.306 \n  \n  \n    AMER_BG2 \n    0.164 \n    0.047 \n    0.286 \n    0.095 \n    0.286 \n  \n  \n    american1 \n    0.369 \n    0.071 \n    0.191 \n    0.254 \n    0.536 \n  \n  \n    american2 \n    0.556 \n    0.123 \n    0.221 \n    0.361 \n    0.854 \n  \n  \n    black_gold1 \n    0.070 \n    0.024 \n    0.342 \n    0.037 \n    0.135 \n  \n  \n    black_gold2 \n    0.112 \n    0.038 \n    0.337 \n    0.059 \n    0.213 \n  \n  \n    bombus1 \n    0.065 \n    0.024 \n    0.374 \n    0.032 \n    0.132 \n  \n  \n    bombus2 \n    0.020 \n    0.010 \n    0.517 \n    0.008 \n    0.052 \n  \n  \n    brown_belted1 \n    0.676 \n    0.134 \n    0.198 \n    0.459 \n    0.995 \n  \n  \n    brown_belted2 \n    0.805 \n    0.167 \n    0.208 \n    0.537 \n    1.207 \n  \n  \n    carpenter1 \n    1.126 \n    0.175 \n    0.155 \n    0.831 \n    1.525 \n  \n  \n    carpenter2 \n    0.551 \n    0.108 \n    0.196 \n    0.376 \n    0.808 \n  \n  \n    eastern1 \n    0.109 \n    0.039 \n    0.358 \n    0.055 \n    0.215 \n  \n  \n    eastern2 \n    0.010 \n    0.008 \n    0.748 \n    0.003 \n    0.038 \n  \n  \n    southern_plains1 \n    0.230 \n    0.058 \n    0.252 \n    0.141 \n    0.375 \n  \n  \n    southern_plains2 \n    0.196 \n    0.063 \n    0.321 \n    0.106 \n    0.363 \n  \n  \n    twsp1 \n    0.060 \n    0.032 \n    0.532 \n    0.022 \n    0.160 \n  \n  \n    unk1 \n    0.300 \n    0.073 \n    0.244 \n    0.187 \n    0.482 \n  \n  \n    unk2 \n    0.107 \n    0.035 \n    0.327 \n    0.057 \n    0.201 \n  \n  \n    Total \n    0.301 \n    0.021 \n    0.070 \n    0.263 \n    0.345 \n  \n\n\n\n\n\nEven though density estimates were produces for these species x bout combinations, their precision would suggest the estimates are not terribly reliable. It is comforting that the imprecision of these estimates is consistent with the small number of detections, even if there is some “borrowing of strength” from other species. This use of covariates may help in the modelling of the detection function, but remember the role that encounter rates and their variability plays in density estimation."
  },
  {
    "objectID": "natalie/pegg.html",
    "href": "natalie/pegg.html",
    "title": "Mourning doves",
    "section": "",
    "text": "1 What are mourning doves up to?\n\n\nStudy Locations\n\nTopeka (east)\nMcPherson (central)\nGarden City (west)\n\nTreatments include \n\nWMAs (wildlife managed areas)\nurban (developed)\nrural\n\n\n\n\n\nMap of Kansas\n\n\n\n\n\n\n2 Get acquainted with data\n\npegg &lt;- read.csv(\"Distance_2024.csv\")"
  },
  {
    "objectID": "natalie/pegg.html#study-locations",
    "href": "natalie/pegg.html#study-locations",
    "title": "Mourning doves",
    "section": "",
    "text": "Topeka (east)\nMcPherson (central)\nGarden City (west)."
  },
  {
    "objectID": "natalie/pegg.html#treatments-include",
    "href": "natalie/pegg.html#treatments-include",
    "title": "Mourning doves",
    "section": "",
    "text": "WMAs (wildlife managed areas)\nurban (developed)\nrural."
  }
]